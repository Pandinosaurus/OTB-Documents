** Classification supervisée pour les séries multi-temporelles       :slides:
*** Objectifs et Données
**** Objectifs
      Les objectifs sont les suivants:
     - Savoir réaliser une classification supervisée
     - Savoir mesurer les performances de la classification
     - Connaître les post-traitements applicables à une classification
**** Données
     Les données sont disponibles dans le répertoire ~Data/classification~, avec les sous-répertoires suivants:
     - ~images~ contient la série multi-temporelle Sentinel2,
     - ~references~ contient la donnée d'apprentissage et de validation au format /shp/,
     - ~support~ contient différents fichiers utiles au TP (fichiers de style Qgis notamment)
     
*** Déroulement
    Les étapes de l'exercice sont les suivantes:
    1. Introduction aux données
    2. Réaliser un apprentissage mono-date
    3. Indentifier la date la plus performante
    4. Réaliser la classification et produire une carte en couleur
    5. Evaluer la performance globale
    6. Régulariser et mesurer le gain de performance
    7. Réaliser une classification multi-date et mesurer le gain de performance
       
*** Présentation des données Sentinel-2

    *Résolution spatiale:* 20 mètres (orignale: 10 mètres)
    *Tuile:* T31TCJ (extrait)
|------------|
| 2016-06-07 |
| 2016-07-07 |
| 2016-08-06 |
| 2016-09-05 |
| 2016-10-05 |
|------------|

*** Présentation des données Sentinel-2

    *Résolution spatiale:* 20 mètres (orignale: 10 mètres)
    *Tuile:* T31TCJ (extrait)

|---+----------------+------------+------------+--------------------|
| # | Band name      | S2 band id | Wavelength | Initial resolution |
|---+----------------+------------+------------+--------------------|
| 0 | Blue           | B2         | 490 nm     | 10 m               |
| 1 | Green          | B3         | 560 nm     | 10 m               |
| 2 | Red            | B4         | 665 nm     | 10 m               |
| 3 | NIR - Narrow 1 | B5         | 705 nm     | 20 m               |
| 4 | NIR - Narrow 2 | B6         | 740 nm     | 20 m               |
| 5 | NIR - Narrow 3 | B7         | 783 nm     | 20 m               |
| 6 | NIR - Wide     | B8         | 842 nm     | 10 m               |
| 7 | NIR - Narrow 4 | B8A        | 865 nm     | 20 m               |
| 8 | SWIR 1         | B11        | 1610 nm    | 20 m               |
| 9 | SWIR 2         | B12        | 2190 nm    | 20 m               |
|---+----------------+------------+------------+--------------------|

*** Présentation des données de référence

|------+-----------------------------+---------------------+--------------------|
| Code | Nom                         | #polygones training | #polygones testing |
|------+-----------------------------+---------------------+--------------------|
|   10 | Cultures annuelles          | 3129                | 3078               |
|   31 | Forêt feuilles caduques     | 176                 | 292                |
|   32 | Forêt feuilles persistantes | 23                  | 29                 |
|   34 | Pelouses                    | 2                   | 2                  |
|   36 | Lande ligneuse              | 63                  | 38                 |
|   41 | Bâti dense                  | 30                  | 33                 |
|   42 | Bâti diffus                 | 326                 | 239                |
|   43 | Zones industrielles         | 154                 | 212                |
|   44 | Routes                      | 162                 | 114                |
|   51 | Eau                         | 243                 | 332                |
|  211 | Prairie                     | 320                 | 311                |
|  221 | Verger                      | 227                 | 254                |
|  222 | Vigne                       | 129                 | 97                 |
|------+-----------------------------+---------------------+--------------------|

*** Classification supervisée
    #+ATTR_LATEX: :float t :width \textwidth
    [[file:Images/classification.png]]
   
*** Algorithme RF
    Ensemble d'arbres de décision aléatoires

**** Apprentissage
     1. Séparer le jeu d'apprentissage en k ensembles $S_k$ aléatoires
     2. Pour chaque $S_k$ choisir aléatoirement $F_k$ primitives
     3. Construire un arbre de décision récursivement, pour chaque noeud:
        1. Choisir $f \in F_k$ et le seuil $t_k$ qui sépare l'ensemble restant en 2 parties les plus pures
        2. Arrêter quand l'ensemble restant devient trop petit
 
**** Décision
     Vote majoritaire de tous les arbres aléatoires


*** Matrice de confusion


|-----------+--------------+--------------+--------------+
|           | Préd. 1      | Préd. 2      | Préd. 3      | 
|-----------+--------------+--------------+--------------+
| Réf. 1    | Vrais pos. 1 |              |              |
| Réf. 2    |              | Vrais pos. 2 |              |
| Réf. 3    |              |              | Vrais pos. 3 |
|-----------+--------------+--------------+--------------+

- $precision = \frac{VP i}{\sum pred. i}$
- $rappel = \frac{VP i}{T\sum ref. i}$
- $Accuracy = \frac{\sum{VP i}}{Total}$
- $Kappa = \frac{Accuracy - chance}{1-chance}$
  
** Classification supervisée pour les séries multi-temporelles        :guide:
*** Description                                                        :desc:
**** Résumé

     Cet exercice permet de se familiariser avec les applications de
     classification supervisée pixellique de l'Orfeo ToolBox, en
     utilisant une série multi-temporelle Sentinel-2 et un jeu de
     données de référence pour la supervision.

**** Pré-requis
     
     - Logiciels installés (Monteverdi et Orfeo ToolBox)
     - Données téléchargées
     - Connaissance du mécanisme des applications de l'Orfeo ToolBox (voir exercice correspondant)
     - Notions de classification supervisée
     
**** Objectifs

     Les objectifs sont les suivants:
     - Connaître les différentes applications constituant la procédure
       de classification supervisée
     - Utiliser différents algorithmes pour l'apprentissage
     - Savoir mesurer les performances de la classification
     - Connaître les post-traitements applicables à une classification

*** Étapes                                                            :steps:

    Les données sont disponibles dans le répertoire ~Data/classification~, avec les sous-répertoires suivants:
     - ~images~ contient la série multi-temporelle Sentinel-2,
     - ~references/training~ contient la donnée d'apprentissage au format /shp/,
     - ~references/testing~ contient la donnée de validation au format /shp/.

**** Présentation des données Sentinel-2

    Dans l'archive de données, le dossier ~Data/classification/images~ contient 5
    images Sentinel-2, extraites de la tuile T31TCJ, aux dates suivantes:
    
|------------|
| 2016-06-07 |
| 2016-07-07 |
| 2016-08-06 |
| 2016-09-05 |
| 2016-10-05 |
|------------|


    Ces images sont toutes multispectrales avec 10 bandes ré-échantillonnnées à 20 m:

|---+----------------+------------+------------+--------------------|
| # | Band name      | S2 band id | Wavelength | Initial resolution |
|---+----------------+------------+------------+--------------------|
| 0 | Blue           | B2         | 490 nm     | 10 m               |
| 1 | Green          | B3         | 560 nm     | 10 m               |
| 2 | Red            | B4         | 665 nm     | 10 m               |
| 3 | NIR - Narrow 1 | B5         | 705 nm     | 20 m               |
| 4 | NIR - Narrow 2 | B6         | 740 nm     | 20 m               |
| 5 | NIR - Narrow 3 | B7         | 783 nm     | 20 m               |
| 6 | NIR - Wide     | B8         | 842 nm     | 10 m               |
| 7 | NIR - Narrow 4 | B8A        | 865 nm     | 20 m               |
| 8 | SWIR 1         | B11        | 1610 nm    | 20 m               |
| 9 | SWIR 2         | B12        | 2190 nm    | 20 m               |
|---+----------------+------------+------------+--------------------|


Au total, c'est donc 50 bandes qui représentent chaque pixel.
Les images sont encodés sur 16 bits.

Ouvrez une image dans monteverdi et régler les bandes pour un affichage en
vrais couleurs (rouge, vert, bleu).

Ouvrez les cinq images et remarquez les changements.

*Note :* Le fichier de style ~support/images.qml~ peut être chargé
dans QGis pour régler la dynamique et la composition colorée de chaque
image à l'identique.

Les fichiers ~references/training/training.shp~ 
et
~references/testing/testing.shp~ contiennent des
polygones qui définissent 13 classes sur l'ensemble de la scène:

|------+-----------------------------+---------------------+--------------------|
| Code | Nom                         | #polygones training | #polygones testing |
|------+-----------------------------+---------------------+--------------------|
|   10 | Cultures annuelles          | 3129                | 3078               |
|   31 | Forêt feuilles caduques     | 176                 | 292                |
|   32 | Forêt feuilles persistantes | 23                  | 29                 |
|   34 | Pelouses                    | 2                   | 2                  |
|   36 | Lande ligneuse              | 63                  | 38                 |
|   41 | Bâti dense                  | 30                  | 33                 |
|   42 | Bâti diffus                 | 326                 | 239                |
|   43 | Zones industrielles         | 154                 | 212                |
|   44 | Routes                      | 162                 | 114                |
|   51 | Eau                         | 243                 | 332                |
|  211 | Prairie                     | 320                 | 311                |
|  221 | Verger                      | 227                 | 254                |
|  222 | Vigne                       | 129                 | 97                 |
|------+-----------------------------+---------------------+--------------------|


    Ouvrez un des fichiers de polygones dans QGIS. La table d'attributs est
    accessible depuis clic-droit sur la couche -> /Ouvrir la table des attributs/.
    Chaque label est visible et la liste est filtrable par expression
    SQL.

    *Note :* Le fichier de style ~support/polygons.qml~ peut être chargé dans
    QGIS pour coloriser les polygones en fonction de leur classe. 

    Les polygones sont répartis en deux ensembles: apprentissage (training) et
    validation (testing).

**** Réaliser un apprentissage mono-date
     
     Nous allons maintenant utiliser l'application
     *TrainImagesClassifier* pafin de réaliser l'apprentissage
     supervisé à partir des données d'entraînement disponibles dans
     ~references/training/training.shp~. Pour commencer, nous allons
     réaliser cet apprentissage avec uniquement l'image du 07.06.2016.

     L'application *TrainImageClassifier* va échantillonner certains
     pixels de l'image contenus dans les polygones de la vérité
     terrain, afin de constituer un ensemble d'apprentissage
     équilibré. Celui-ci est ensuite transmis à l'algorithme
     d'apprentissage.

     Cette application prend en paramètres obligatoires:
     - L'image dont les bandes seront utilisées comme descripteurs
       pour l'algorithme de classification,
     - La couche vecteur contenant les polygones de référence,
     - Le nom du champ correspondant à la classe d'occupation du sol
       dans cette couche vecteur,
     - Le fichier sortie ou stocker le modèle appris (on peut
       l'appeler ~model.rf~).

     Régler certains paramètres optionnels comme suit:
     - Le classifieur "Random Forests" pour comme algorithme
       d'apprentissage,
     - Le nombre d'arbre à 50,
     - La profondeur maximale de l'arbre à 20,
     - Le nombre minimum d'échantillons pour chaque noeud à 70,
     - Le nombre de cluster à 13 (équivalent au nombre de classes)

     Examiner les logs de l'application, en particulier la matrice de
     confusion, la valeur du coefficient Kappa et les scores par
     classe. Que constatez-vous ? En l'absence de polygones dédiés à
     la validation, l'application utilise une partie des échantillons
     générés pour la validation. Que peut on en déduire quand aux
     performances affichées ?

     Refaire l'apprentissage, cette fois en utilisant les données de
     validation ~reference/testing/testing.shp~ comme vecteur de
     validation (vous donnez donc à l'application deux fichiers shp
     différents). Que constatez vous ?

**** Identifier la date la plus performante

     Réitérer l'apprentissage pour chacune des dates. Quelle date
     fournit la meilleure performance ? Le coefficient Kappa
     change-t-il beaucoup ?

**** Réaliser la classification et produire une carte en couleur
     
     Utiliser l'application *ImageClassifier* pour produire la carte
     de classification correspondant à la meilleure date
     (celle du 05.09.2016). Attention à bien utiliser le fichier de modèle
     correspondant entraîné à partir de cette date.

     La sortie de l'étape précédente est une image .tif qui associe à
     chaque pixel une classe. Pour visualiser cette image, l'application
     *ColorMapping* permet d'associer à chaque label une couleur RGB et de
     générer une image de visualisation.  
     
     Utilisez le mode *custom* l'application *ColorMapping* avec la table de couleur fournie
     ~support/color_map.txt~ pour produire une carte colorisée.
     
     # TODO: vérifier si la note suivante est toujours nécessaire ?
     *Note :* Il se peut que l'image ne s'affiche pas correctement dans
     Qgis, du fait d'une valeur non renseignée (no data) par défaut enregistrée dans le
     fichier. La prise en compte du nodata peut être désactivé dans les
     propriétés de la couche dans Qgis.
     
**** Évaluer la performance globale

     Nous allons maintenant utiliser l'application
     *ComputeConfusionMatrix* afin de calculer la performance globale
     de la classification. Par rapport à l'évaluation des
     performances réalisée lors de l'apprentissage, cette application
     permet de:
     - Prendre en compte l'ensemble des pixels disponibles dans la donnée de référence,
     - Évaluer la performance d'une carte de classification qui a été
    retraitée (par exemple avec une régularisation).
    
    Le paramètre ~ref.vector.field CODE~ est nécessaire. Il indique le
    nom du champ contenant le numéro de label.

    Calculer la performance globale de la classification. Que
     constatez vous par rapport à la performance évaluée lors de la
     phase d'entraînement ? Comment expliquer ce phénomène ?
     
**** Régulariser et mesurer le gain de performance

     Nous allons utiliser l'application *ClassificationMapRegularization*. Elle
     filtre une image classifiée en utilisant un vote majoritaire local.

     Les paramètres à régler sont:

  - ip.radius 1 :: Rayon de la zone participant au vote
  - ip.suvbool 0 :: Que faire lors d'une égalité. 0 pour utiliser la valeur existante.

  Filtrez le résultat de la classification précédente. Evaluer la
  performance globale de la carte de classification filtrée. Que
  constatez-vous ?

**** Réaliser une classification multi-date et mesurer le gain de performance

     Nous allons maintenant utiliser l'ensemble des dates pour la
     classification. A cet effet, vous pouvez utiliser le fichier
     ~images/all.vrt~ qui contient l'ensemble des bandes de chaque
     dates concaténées (c'est donc une image à 50 bandes). 

     Rejouer l'ensemble du TP avec cette image de 50 bandes. Quel est
     l'apport de la série multi-temporel pour la performance de
     classification ?

     Comparez dans Qgis les deux cartes de classification régularisées.

**** Pour aller plus loin

     1) Peut on obtenir de meilleure performance avec d'autres
        algorithmes de classification ?
     
     2) A l'aide de Qgis, fusionner dans la donnée de référence les
        classes pelouse et lande ligneuse. Quelle performance obtenez
        vous ?

     3) L'application ~TrainImagesClassifier~ contient également un
        algorithme de classification non-supervisée (Shark
        KMeans). Comparer le résultat d'une classification supervisée
        et non-supervisée avec la même image. 

** Classification supervisée pour les séries multi-temporelles    :solutions:

*Note :* Dans cette solution, la variable d'environnement ~${LS8DATA}~
contient le chemin vers le répertoire /classification/ des données
fournies avec le TP.

*** Préparation des données

    Tout d'abord, nous concaténons l'ensemble des bandes pour toutes
    les dates:

    #+BEGIN_EXAMPLE
    $ otbcli_ConcatenateImages -il ${LS8DATA}/LANDSAT_*.tif -out alldates.tif uint16
    #+END_EXAMPLE

    Ensuite, nous calculons pour chaque date le NDVI correspondant:
    
    #+BEGIN_EXAMPLE
    $ cd ${LS8DATA}
    $ for f in LANDSAT_*.tif; do \
        otbcli_RadiometricIndices -channels.blue 2 -channels.green 3 \
                                  -channels.red 4 -channels.nir 5    \
                                  -in "$f" -out "NDVI_$f" -list Vegetation:NDVI; done
    #+END_EXAMPLE

    Nous pouvons ensuite créer le profil de NDVI:

    #+BEGIN_EXAMPLE
    $ otbcli_ConcatenateImages -il ${LS8DATA}/NDVI_*.tif -out ndvis.tif
    #+END_EXAMPLE

    Ainsi que l'image contenant l'ensemble des bandes et le profil de
    NDVI:

    #+BEGIN_EXAMPLE
    $ otbcli_ConcatenateImages -il alldates.tif ndvis.tif -out all.tif
    #+END_EXAMPLE
    
*** Calcul des statistiques des échantillons disponibles

    Le calcul des statistiques des échantillons disponibles se réalise
     de la manière suivante :

    #+BEGIN_EXAMPLE
    $ otbcli_PolygonClassStatistics -in Extract16bits/alldates.tif \
                                    -field CODE -vec training/training.shp \
                                    -out training_stats.xml

    $ otbcli_PolygonClassStatistics -in Extract16bits/alldates.tif \
                                    -field CODE -vec testing/testing.shp \
                                     -out testing_stats.xml
    #+END_EXAMPLE

    En inspectant les fichiers XML ~training_stats.xml~ et
    ~validation_stats.xml~, on peut trouver les informations suivantes:

    Dans le fichier ~training_stats.xml~:

    #+BEGIN_EXAMPLE
    <Statistic name="samplesPerClass">
        <StatisticMap key="11" value="56774" />
        <StatisticMap key="12" value="59347" />
        <StatisticMap key="211" value="25317" />
        <StatisticMap key="221" value="2087" />
        <StatisticMap key="222" value="2080" />
        <StatisticMap key="31" value="8149" />
        <StatisticMap key="32" value="1029" />
        <StatisticMap key="34" value="3770" />
        <StatisticMap key="36" value="941" />
        <StatisticMap key="41" value="2630" />
        <StatisticMap key="51" value="11221" />
    </Statistic>
    #+END_EXAMPLE

    La classe prairie (label 211) possède donc 25 317 échantillons
    disponibles.  On peut également noter que le jeux d'apprentissage
    contient 173 345 échantillons, et que la classe lande ligneuse
    (label 36) est la classe qui en contient le moins, avec seulement
    941 échantillons.

    Le polygone dont l'identifiant est 1081 dans le jeu
    d'apprentissage contient 342 échantillons:

    #+BEGIN_EXAMPLE
    <StatisticMap key="1081" value="342" />
    #+END_EXAMPLE

    Dans le fichier ~testing_stats.xml~:

    #+BEGIN_EXAMPLE
    <Statistic name="samplesPerClass">
        <StatisticMap key="11" value="134590" />
        <StatisticMap key="12" value="127548" />
        <StatisticMap key="211" value="59052" />
        <StatisticMap key="221" value="4820" />
        <StatisticMap key="222" value="6393" />
        <StatisticMap key="31" value="18620" />
        <StatisticMap key="32" value="2121" />
        <StatisticMap key="34" value="9351" />
        <StatisticMap key="36" value="2812" />
        <StatisticMap key="41" value="6110" />
        <StatisticMap key="51" value="28858" />
    </Statistic>
    #+END_EXAMPLE

    La classe prairie (label 211) possède donc 59 052 échantillons
    disponibles.

*** Sélection des positions des échantillons

    D'après la documentation de l'application, les différentes
    stratégies possibles pour pour réaliser l'échantillonnage des
    données d'apprentissage sont :
    - byclass :: Indiquer pour chaque classe le nombre d'échantillons
                 à sélectionner (par le biais d'un fichier)
    - constant :: Indiquer un nombre constant d'échantillons appliqué
                  à toutes les classes
    - smallest :: Sélectionner un nombre constant d'échantillons
                  appliqué à toute les classes de sorte que la classe
                  la plus petite soit échantillonnée complètement.
    - all :: Sélectionner tous les échantillons. 

 
    Pour réaliser la sélection des échantillons avec la stratégie
    /smallest/, on procède comme suit:

    #+BEGIN_EXAMPLE
    $ otbcli_SampleSelection -in alldates.tif -field CODE \
                             -vec training/training.shp   \
                             -out training_samples.sqlite \
                             -instats training_stats.xml -strategy smallest
    #+END_EXAMPLE

  Voici l'échantillonnage réalisé par l'application (chiffres extraits
  des logs):
    
  |-----------+-----------------+--------------+-----------|
  | className | requiredSamples | totalSamples |      rate |
  |-----------+-----------------+--------------+-----------|
  |        11 |             941 |        56774 | 0.0165745 |
  |        12 |             941 |        59347 | 0.0158559 |
  |       211 |             941 |        25317 | 0.0371687 |
  |       221 |             941 |         2087 |  0.450886 |
  |       222 |             941 |         2080 |  0.452404 |
  |        31 |             941 |         8149 |  0.115474 |
  |        32 |             941 |         1029 |   0.91448 |
  |        34 |             941 |         3770 |  0.249602 |
  |        36 |             941 |          941 |         1 |
  |        41 |             941 |         2630 |  0.357795 |
  |        51 |             941 |        11221 | 0.0838606 |
  |-----------+-----------------+--------------+-----------|

  Au total, 10 351 échantillons ont été sélectionnés. Si on ouvre la
  couche dans Qgis, on peut se faire une idée de l'échantillonnage qui
  a été réalisé.
  
  #+ATTR_LATEX: :width 0.9\textwidth
  [[file:Images/samples_selection.png]]

  Les attributs associés à chaque point sont les attributs du fichier
  vecteur d'origine ~training.shp~, ainsi que l'attribut ~originfid~
  qui correspond à l'identifiant du polygone ou l'échantillon a été
  sélectionné.

*** Calcul des attributs des échantillons

    Pour calculer les attributs associés à chaque échantillon, on
    procède de la manière suivante. Pour les bandes de l'image:

    #+BEGIN_EXAMPLE
    $ otbcli_SampleExtraction -in alldates.tif               \
                              -vec training_samples.sqlite   \
                              -outfield prefix               \
                              -outfield.prefix.name band_    \
                              -field code

    $ otbcli_SampleExtraction -in ndvis.tif                  \
                              -vec training_samples.sqlite   \
                              -outfield prefix               \
                              -outfield.prefix.name ndvi_    \
                              -field code
    #+END_EXAMPLE

    On procède de la même manière pour le jeu de validation.

    #+BEGIN_EXAMPLE
    $ otbcli_SampleExtraction -in alldates.tif               \
                              -vec testing_samples.sqlite   \
                              -outfield prefix               \
                              -outfield.prefix.name band_    \
                              -field code 

    $ otbcli_SampleExtraction -in ndvis.tif                  \
                              -vec testing_samples.sqlite   \
                              -outfield prefix               \
                              -outfield.prefix.name ndvi_    \
                              -field code 
    #+END_EXAMPLE

*** Entraînement du modèle

    Nous utiliserons dans cette partie les variables shell proposées
    dans l'énoncé.

    L'apprentissage se réalise de la manière suivante:
    
    #+BEGIN_EXAMPLE
    $ otbcli_TrainVectorClassifier -io.vd training_samples.sqlite \
                                   -cfield code -classifier rf    \
                                   -classifier.rf.max 20          \
                                   -io.out model.rf -feat ${date1}
    #+END_EXAMPLE

    Cette première exécution donne les résultats suivants:

    #+BEGIN_EXAMPLE
    Confusion matrix (rows = reference labels, columns = produced labels):
      [11] [12] [31] [32] [34] [36] [41] [51] [211] [221] [222] 
[ 11]   861    28     2     0     8     5     3     0     5     6    24 
[ 12]    16   889     3     1     3     2     1     2     5    12     7 
[ 31]     8    10   873     5     9    19     2     0     6     9     0 
[ 32]     4     0    21   895     6     3     2     3     1     4     2 
[ 34]    12    20    39     9   785    19     8     1    19    17    12 
[ 36]    10    30    46    11    21   771     8     1    20     9    14 
[ 41]     4    13     8     4     5     1   862     3    16    17     8 
[ 51]     2    11     2     0     4     2     5   906     2     7     0 
[211]     2    27    35     5    21    32     2     1   782    15    19 
[221]    13    14     5     3     7     4     8     6    11   845    25 
[222]    15    24     2     0     2     8     0     0    16    14   860 

[...]

Global performance, Kappa index: 0.891296 
    #+END_EXAMPLE
    
    La raison pour laquelle le coefficient Kappa est si élevé malgré
    l'emploi d'une unique date d'acquisition est qu'en l'absence
    d'échantillons de validation, l'application évalue les
    performances en utilisant le jeu d'apprentissage. Pour obtenir une
    évaluation plus réaliste des performances, on peut utiliser pour
    la validation le fichier ~testing_samples.sqlite~ que nous avons
    créé précédemment:

    #+BEGIN_EXAMPLE
    $ otbcli_TrainVectorClassifier -io.vd training_samples.sqlite   \
                                   -valid.vd testing_samples.sqlite \
                                   -cfield code -classifier rf      \
                                   -classifier.rf.max 20            \
                                   -io.out model.rf -feat ${date1}
    #+END_EXAMPLE
    

    Dans ce cas, les résultats sont les suivants:

    
    #+BEGIN_EXAMPLE
     [11] [12] [31] [32] [34] [36] [41] [51] [211] [221] [222] 
[ 11]  1504   285     9     1    32    40    43     3    43    36   126 
[ 12]   183  1619    13     8    15    25     9     5    59    77   108 
[ 31]    26    60  1463    89    76   237    38    30    33    65     4 
[ 32]    47    54   362  1478    49    31    23    16    26    29     6 
[ 34]    45    45   364   230   252   620    21    19   270   110   145 
[ 36]    85   164   232    65   421   647    27     6   214   135   125 
[ 41]    49    79    51    32    49    20  1559    29    61   128    64 
[ 51]    27    39    26    17     7    19    44  1919     6    17     0 
[211]    21   131   113    29   274   143    11     6  1086    66   241 
[221]    93   165   113    93   201   148    95    12   196   771   234 
[222]   164   229     8     4    91    58    10     1   181   123  1252

[...]

Global performance, Kappa index: 0.538822
#+END_EXAMPLE

Ces résultats montrent que les performances sont moyennes en utilisant
une unique date.

Pour tester différentes configurations, on peut utiliser les variables
définies dans l'énoncé et les passer au paramètre ~-feat~. Par exemple
pour tester les deux premières dates, on peut utiliser ~-feat ${date1}
${date2}~.

**** Quelle date fournit la meilleure performance individuelle ?

La meilleure date est la troisième date (2014-04-17), avec un Kappa de 0.578.

|------------+----------|
|       Date |    Kappa |
|------------+----------|
| 2014-03-09 | 0.538822 |
| 2014-04-01 | 0.560085 |
| 2014-04-17 | 0.578801 |
| 2014-05-28 |  0.56494 |
| 2014-06-20 | 0.560509 |
| 2014-07-31 | 0.540943 |
| 2014-09-01 | 0.555276 |
| 2014-10-03 | 0.530006 |
| 2014-10-26 | 0.494788 |
|------------+----------|

Ce tableau a été obtenu avec le script bash suivant:

#+BEGIN_EXAMPLE
$ for i in $(seq 1 9); do var=date$i; otbcli_TrainVectorClassifier    \
                                     -io.vd training_samples.sqlite   \
                                     -valid.vd testing_samples.sqlite \
                                     -cfield code -classifier rf      \
                                     -classifier.rf.max 20            \
                                     -io.out model.rf -feat ${!var}   \
                                     | grep Kappa; done
#+END_EXAMPLE

**** La bande bleu côtier a-t-elle un intérêt pour la classification ?

     En utilisant le paramètre ~-feat ${date1}~ on obtient un Kappa
     de 0.538822 pour la première date, tandis que si l'on retire la
     bande bleu côtier en utilisant ~-feat ${date1_nocb}~ on obtient un
     Kappa de 0.538068. On peut donc conclure que la bande bleu côtier
     n'apporte que très peu d'information (et donc de performance) au
     problème de classification.

**** Quelle est la performance en utilisant toutes les bandes spectrales ?
     
     En utilisant le paramètre ~-feat ${dates}~, on obtient un Kappa
     de 0.677147.

**** Quelle est la performance du profil de NDVI seul ?

     En utilisant le paramètre ~-feat ${ndvis}~ on obtient un Kappa de
     0.554286. En utilisant seulement 9 valeurs d'indice
     radiométrique, on fait donc seulement 0.12 points de Kappa en
     moins par rapport à l'ensemble des 63 bandes spectrales. On fait
     également aussi bien, voire mieux que certaines dates individuelles
     (qui contiennent chacune 7 bandes).

**** Quelle est la performance en utilisant toutes les bandes spectrales et le profil de NDVI ?

     En utilisant le paramètre ~-feat ${bands} ${ndvis}~ on obtient un
     Kappa de 0.682333, soit légèrement mieux que les bandes
     spectrales seules.

**** Dans ce dernier cas, analyser les performances par classe

     La classe eau (label 51) est la mieux reconnue, avec un F-score
     de 0.945575.

     Les classes pelouse (label 34) et landes ligneuses (label 36)
     sont de loin les moins bien reconnues, avec un F-score respectif
     de 0.278807 et 0.428884. Toutes les autres classes ont un F-score
     parfois très supérieur à 0.6.

     Si l'on analyse plus finement la matrice de confusion, on peut
     constater que ces deux classes sont souvent confondues par le
     modèle: 24% des échantillons de pelouse sont classés comme lande
     ligneuse (et 17% comme prairie), tandis que 22% des échantillons
     de lande ligneuse sont classés comme pelouse (et 10% comme
     prairie). 

*** Classification

    Pour réaliser la carte de classification, on va utiliser le modèle
    appris sur l'ensemble des bandes spectrales et du profil de NDVI
    (dans cet ordre). Attention, l'ordre des attributs utilisés lors
    de l'apprentissage doit être le même que l'ordre des bandes
    fournies en entrée de l'application *ImageClassifier*.

    #+BEGIN_EXAMPLE
    $ otbcli_ImageClassifier -in Extract16bits/all.tif \
                             -out classif.tif uint8 \
                             -model model.rf
    #+END_EXAMPLE

*** Post-traitement de la classification

    Pour régulariser la carte de classification, on utilise l'appel
    suivant:

    #+BEGIN_EXAMPLE
    $ otbcli_ClassificationMapRegularization -ip.radius 1 -ip.suvbool 0    \
                                             -io.in classif.tif            \
                                             -io.out classif_reg.tif uint8 
    #+END_EXAMPLE

    On peut observer visuellement l'effet de cette régularisation
    (attention à décocher l'utilisation des valeurs nulles (nodata)
    dans Qgis), mais il est également intéressant de connaître
    l'impact de cette opération sur les performances, ce que nous
    allons faire dans la section suivante.

*** Évaluation complète des performances

    Pour évaluer les performances sur l'ensemble de la donnée de
    validation, on utilise l'application *ComputeConfusionMatrix*.

    Sur la carte de classification brute :

    #+BEGIN_EXAMPLE
    $ otbcli_ComputeConfusionMatrix -in classif.tif -ref vector        \
                                    -ref.vector.in testing/testing.shp \
                                    -out confusion.csv                 \
                                    -ref.vector.field CODE
    #+END_EXAMPLE

    Cette évaluation complète donne un Kappa de 0.803679. Cette valeur
    est bien plus élevée que celle évaluée lors de la phase
    d'entraînement, qui atteignait seulement 0.682333. Ceci s'explique
    par le fait que la donnée de validation utilisée lors de la phase
    d'entraînement a été générée avec la stratégie /smallest/ qui
    produit le même nombre d'échantillon pour chaque classe. Or, si
    l'on regarde les statistiques produites en début de TP, on peut
    voir que les classes cultures d'été (11) cultures d'hiver (12) et
    eau (51) sont sur-représentées dans la donnée de référence. Or, ces
    trois classes ont également les meilleures performances de
    classifications. Leurs sur-représentation tire donc la performance
    globale vers le haut. On aurait pu générer le jeu de validation
    avec la stratégie /all/, ce qui aurait permis d'estimer cette
    performance finale dès la phase d'entraînement. Cependant, ceci
    aurait éventuellement masqué les faibles performances de certaines
    classes.

    Sur la carte de classification régularisée :

    #+BEGIN_EXAMPLE
    $ otbcli_ComputeConfusionMatrix -in classif_reg.tif -ref vector    \
                                    -ref.vector.in testing/testing.shp \
                                    -out confusion.csv                 \
                                    -ref.vector.field CODE
    #+END_EXAMPLE

    Cette fois, le Kappa mesuré est de 0.873691. On peut donc
    conclure que la régularisation améliore les performances de la
    classification, car celle-ci est alors morphologiquement plus
    proche de la donnée de référence, qui est régulière.

*** Production d'une carte de classification en couleur
    
    Pour produire la carte colorisée, on utilise l'appel suivant:

    #+BEGIN_EXAMPLE
    $ otbcli_ColorMapping -in classif_reg.tif -out classif_reg_rgb.tif uint8 \
                          -method custom -method.custom.lut color_map.txt
    #+END_EXAMPLE
    
    #+ATTR_LATEX: :width 0.9\textwidth
    [[file:Images/final_classification.png]]
