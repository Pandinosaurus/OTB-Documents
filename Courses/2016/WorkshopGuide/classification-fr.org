** Classification supervisée pour les séries multi-temporelles       :slides:
*** Objectifs et Données
**** Objectifs
      Les objectifs sont les suivants:
     - Savoir réaliser une classification supervisée
     - Savoir mesurer les performances de la classification
     - Connaître les post-traitements applicables à une classification
**** Données
     Les données sont disponibles dans le répertoire ~Data/classification~, avec les sous-répertoires suivants:
     - ~images~ contient la série multi-temporelle Sentinel2,
     - ~references~ contient la donnée d'apprentissage et de validation au format /shp/,
     - ~support~ contient différents fichiers utiles au TP (fichiers de style Qgis notamment)
     
*** Déroulement
    Les étapes de l'exercice sont les suivantes:
    1. Introduction aux données
    2. Réaliser un apprentissage mono-date
    3. Indentifier la date la plus performante
    4. Réaliser la classification et produire une carte en couleur
    5. Evaluer la performance globale
    6. Régulariser et mesurer le gain de performance
    7. Réaliser une classification multi-date et mesurer le gain de performance
       
*** Présentation des données Sentinel-2

    *Résolution spatiale:* 20 mètres (orignale: 10 mètres)
    *Tuile:* T31TCJ (extrait)
|------------|
| 2016-06-07 |
| 2016-07-07 |
| 2016-08-06 |
| 2016-09-05 |
| 2016-10-05 |
|------------|

*** Présentation des données Sentinel-2

    *Résolution spatiale:* 20 mètres (orignale: 10 mètres)
    *Tuile:* T31TCJ (extrait)

|---+----------------+------------+------------+--------------------|
| # | Band name      | S2 band id | Wavelength | Initial resolution |
|---+----------------+------------+------------+--------------------|
| 0 | Blue           | B2         | 490 nm     | 10 m               |
| 1 | Green          | B3         | 560 nm     | 10 m               |
| 2 | Red            | B4         | 665 nm     | 10 m               |
| 3 | NIR - Narrow 1 | B5         | 705 nm     | 20 m               |
| 4 | NIR - Narrow 2 | B6         | 740 nm     | 20 m               |
| 5 | NIR - Narrow 3 | B7         | 783 nm     | 20 m               |
| 6 | NIR - Wide     | B8         | 842 nm     | 10 m               |
| 7 | NIR - Narrow 4 | B8A        | 865 nm     | 20 m               |
| 8 | SWIR 1         | B11        | 1610 nm    | 20 m               |
| 9 | SWIR 2         | B12        | 2190 nm    | 20 m               |
|---+----------------+------------+------------+--------------------|

*** Présentation des données de référence

|------+-----------------------------+---------------------+--------------------|
| Code | Nom                         | #polygones training | #polygones testing |
|------+-----------------------------+---------------------+--------------------|
|   10 | Cultures annuelles          | 3129                | 3078               |
|   31 | Forêt feuilles caduques     | 176                 | 292                |
|   32 | Forêt feuilles persistantes | 23                  | 29                 |
|   34 | Pelouses                    | 2                   | 2                  |
|   36 | Lande ligneuse              | 63                  | 38                 |
|   41 | Bâti dense                  | 30                  | 33                 |
|   42 | Bâti diffus                 | 326                 | 239                |
|   43 | Zones industrielles         | 154                 | 212                |
|   44 | Routes                      | 162                 | 114                |
|   51 | Eau                         | 243                 | 332                |
|  211 | Prairie                     | 320                 | 311                |
|  221 | Verger                      | 227                 | 254                |
|  222 | Vigne                       | 129                 | 97                 |
|------+-----------------------------+---------------------+--------------------|

*** Classification supervisée
    #+ATTR_LATEX: :float t :width \textwidth
    [[file:Images/classification.png]]
   
*** Algorithme RF
    Ensemble d'arbres de décision aléatoires

**** Apprentissage
     1. Séparer le jeu d'apprentissage en k ensembles $S_k$ aléatoires
     2. Pour chaque $S_k$ choisir aléatoirement $F_k$ primitives
     3. Construire un arbre de décision récursivement, pour chaque noeud:
        1. Choisir $f \in F_k$ et le seuil $t_k$ qui sépare l'ensemble restant en 2 parties les plus pures
        2. Arrêter quand l'ensemble restant devient trop petit
 
**** Décision
     Vote majoritaire de tous les arbres aléatoires


*** Matrice de confusion


|-----------+--------------+--------------+--------------+
|           | Préd. 1      | Préd. 2      | Préd. 3      | 
|-----------+--------------+--------------+--------------+
| Réf. 1    | Vrais pos. 1 |              |              |
| Réf. 2    |              | Vrais pos. 2 |              |
| Réf. 3    |              |              | Vrais pos. 3 |
|-----------+--------------+--------------+--------------+

- $precision = \frac{VP i}{\sum pred. i}$
- $rappel = \frac{VP i}{T\sum ref. i}$
- $Accuracy = \frac{\sum{VP i}}{Total}$
- $Kappa = \frac{Accuracy - chance}{1-chance}$
  
** Classification supervisée pour les séries multi-temporelles        :guide:
*** Description                                                        :desc:
**** Résumé

     Cet exercice permet de se familiariser avec les applications de
     classification supervisée pixellique de l'Orfeo ToolBox, en
     utilisant une série multi-temporelle Sentinel-2 et un jeu de
     données de référence pour la supervision.

**** Pré-requis
     
     - Logiciels installés (Monteverdi et Orfeo ToolBox)
     - Données téléchargées
     - Connaissance du mécanisme des applications de l'Orfeo ToolBox (voir exercice correspondant)
     - Notions de classification supervisée
     
**** Objectifs

     Les objectifs sont les suivants:
     - Connaître les différentes applications constituant la procédure
       de classification supervisée
     - Utiliser différents algorithmes pour l'apprentissage
     - Savoir mesurer les performances de la classification
     - Connaître les post-traitements applicables à une classification

*** Étapes                                                            :steps:

    Les données sont disponibles dans le répertoire ~Data/classification~, avec les sous-répertoires suivants:
     - ~images~ contient la série multi-temporelle Sentinel-2,
     - ~references/training~ contient la donnée d'apprentissage au format /shp/,
     - ~references/testing~ contient la donnée de validation au format /shp/.

**** Présentation des données Sentinel-2

    Dans l'archive de données, le dossier ~Data/classification/images~ contient 5
    images Sentinel-2, extraites de la tuile T31TCJ, aux dates suivantes:
    
|------------|
| 2016-06-07 |
| 2016-07-07 |
| 2016-08-06 |
| 2016-09-05 |
| 2016-10-05 |
|------------|


    Ces images sont toutes multispectrales avec 10 bandes ré-échantillonnnées à 20 m:

|---+----------------+------------+------------+--------------------|
| # | Band name      | S2 band id | Wavelength | Initial resolution |
|---+----------------+------------+------------+--------------------|
| 0 | Blue           | B2         | 490 nm     | 10 m               |
| 1 | Green          | B3         | 560 nm     | 10 m               |
| 2 | Red            | B4         | 665 nm     | 10 m               |
| 3 | NIR - Narrow 1 | B5         | 705 nm     | 20 m               |
| 4 | NIR - Narrow 2 | B6         | 740 nm     | 20 m               |
| 5 | NIR - Narrow 3 | B7         | 783 nm     | 20 m               |
| 6 | NIR - Wide     | B8         | 842 nm     | 10 m               |
| 7 | NIR - Narrow 4 | B8A        | 865 nm     | 20 m               |
| 8 | SWIR 1         | B11        | 1610 nm    | 20 m               |
| 9 | SWIR 2         | B12        | 2190 nm    | 20 m               |
|---+----------------+------------+------------+--------------------|


Au total, c'est donc 50 bandes qui représentent chaque pixel.
Les images sont encodés sur 16 bits.

Ouvrez une image dans monteverdi et régler les bandes pour un affichage en
vrais couleurs (rouge, vert, bleu).

Ouvrez les cinq images et remarquez les changements.

*Note :* Le fichier de style ~support/images.qml~ peut être chargé
dans QGis pour régler la dynamique et la composition colorée de chaque
image à l'identique.

Les fichiers ~references/training/training.shp~ 
et
~references/testing/testing.shp~ contiennent des
polygones qui définissent 13 classes sur l'ensemble de la scène:

|------+-----------------------------+---------------------+--------------------|
| Code | Nom                         | #polygones training | #polygones testing |
|------+-----------------------------+---------------------+--------------------|
|   10 | Cultures annuelles          | 3129                | 3078               |
|   31 | Forêt feuilles caduques     | 176                 | 292                |
|   32 | Forêt feuilles persistantes | 23                  | 29                 |
|   34 | Pelouses                    | 2                   | 2                  |
|   36 | Lande ligneuse              | 63                  | 38                 |
|   41 | Bâti dense                  | 30                  | 33                 |
|   42 | Bâti diffus                 | 326                 | 239                |
|   43 | Zones industrielles         | 154                 | 212                |
|   44 | Routes                      | 162                 | 114                |
|   51 | Eau                         | 243                 | 332                |
|  211 | Prairie                     | 320                 | 311                |
|  221 | Verger                      | 227                 | 254                |
|  222 | Vigne                       | 129                 | 97                 |
|------+-----------------------------+---------------------+--------------------|


    Ouvrez un des fichiers de polygones dans QGIS. La table d'attributs est
    accessible depuis clic-droit sur la couche -> /Ouvrir la table des attributs/.
    Chaque label est visible et la liste est filtrable par expression
    SQL.

    *Note :* Le fichier de style ~support/polygons.qml~ peut être chargé dans
    QGIS pour coloriser les polygones en fonction de leur classe. 

    Les polygones sont répartis en deux ensembles: apprentissage (training) et
    validation (testing).

**** Réaliser un apprentissage mono-date
     
     Nous allons maintenant utiliser l'application
     *TrainImagesClassifier* pafin de réaliser l'apprentissage
     supervisé à partir des données d'entraînement disponibles dans
     ~references/training/training.shp~. Pour commencer, nous allons
     réaliser cet apprentissage avec uniquement l'image du 07.06.2016.

     L'application *TrainImageClassifier* va échantillonner certains
     pixels de l'image contenus dans les polygones de la vérité
     terrain, afin de constituer un ensemble d'apprentissage
     équilibré. Celui-ci est ensuite transmis à l'algorithme
     d'apprentissage.

     Cette application prend en paramètres obligatoires:
     - L'image dont les bandes seront utilisées comme descripteurs
       pour l'algorithme de classification,
     - La couche vecteur contenant les polygones de référence,
     - Le nom du champ correspondant à la classe d'occupation du sol
       dans cette couche vecteur,
     - Le fichier sortie ou stocker le modèle appris (on peut
       l'appeler ~model.rf~).

     Régler certains paramètres optionnels comme suit:
     - Le classifieur "Random Forests" pour comme algorithme
       d'apprentissage,
     - Le nombre d'arbres à 50,
     - La profondeur maximale de l'arbre à 20,
     - Le nombre minimum d'échantillons pour chaque noeud à 70,
     - Le nombre de clusters à 13 (équivalent au nombre de classes)

     Examiner les logs de l'application, en particulier la matrice de
     confusion, la valeur du coefficient Kappa et les scores par
     classe. Que constatez-vous ? En l'absence de polygones dédiés à
     la validation, l'application utilise une partie des échantillons
     générés pour la validation. Que peut on en déduire quand aux
     performances affichées ?

     Refaire l'apprentissage, cette fois en utilisant les données de
     validation ~reference/testing/testing.shp~ comme vecteur de
     validation (vous donnez donc à l'application deux fichiers shp
     différents). Que constatez vous ?

     Refaire l'apprentissage, en désactivant l'option
     ~cleanup~. Regardez les données intermédiaires qui ont été
     générées. A quoi correspondent elles ?

**** Identifier la date la plus performante

     Réitérer l'apprentissage pour chacune des dates. Quelle date
     fournit la meilleure performance ? Le coefficient Kappa
     change-t-il beaucoup ?

     Rejouer l'apprentissage correspondant à la meilleure date afin de
     conserver le fichier de modèle ~model.rf~.

**** Réaliser la classification et produire une carte en couleur
     
     Utiliser l'application *ImageClassifier* pour produire la carte
     de classification correspondant à la meilleure date
     (celle du 05.09.2016). Attention à bien utiliser le fichier de modèle
     correspondant entraîné à partir de cette date.

     La sortie de l'étape précédente est une image .tif qui associe à
     chaque pixel une classe. Pour visualiser cette image, l'application
     *ColorMapping* permet d'associer à chaque label une couleur RGB et de
     générer une image de visualisation.  
     
     Utilisez le mode *custom* l'application *ColorMapping* avec la table de couleur fournie
     ~support/color_map.txt~ pour produire une carte colorisée.
     
     # TODO: vérifier si la note suivante est toujours nécessaire ?
     *Note :* Il se peut que l'image ne s'affiche pas correctement dans
     Qgis, du fait d'une valeur non renseignée (no data) par défaut enregistrée dans le
     fichier. La prise en compte du nodata peut être désactivé dans les
     propriétés de la couche dans Qgis.
     
**** Évaluer la performance globale

     Nous allons maintenant utiliser l'application
     *ComputeConfusionMatrix* afin de calculer la performance globale
     de la classification. Par rapport à l'évaluation des
     performances réalisée lors de l'apprentissage, cette application
     permet de:
     - Prendre en compte l'ensemble des pixels disponibles dans la donnée de référence,
     - Évaluer la performance d'une carte de classification qui a été
    retraitée (par exemple avec une régularisation).
    
    Le paramètre ~ref.vector.field CODE~ est nécessaire. Il indique le
    nom du champ contenant le numéro de label.

    Calculer la performance globale de la classification. Que
     constatez vous par rapport à la performance évaluée lors de la
     phase d'entraînement ? Comment expliquer ce phénomène ?
     
**** Régulariser et mesurer le gain de performance

     Nous allons utiliser l'application *ClassificationMapRegularization*. Elle
     filtre une image classifiée en utilisant un vote majoritaire local.

     Les paramètres à régler sont:

  - ip.radius 1 :: Rayon de la zone participant au vote
  - ip.suvbool 0 :: Que faire lors d'une égalité. 0 pour utiliser la valeur existante.

  Filtrez le résultat de la classification précédente. Evaluer la
  performance globale de la carte de classification filtrée. Que
  constatez-vous ?

**** Réaliser une classification multi-date et mesurer le gain de performance

     Nous allons maintenant utiliser l'ensemble des dates pour la
     classification. A cet effet, vous pouvez utiliser le fichier
     ~images/all.vrt~ qui contient l'ensemble des bandes de chaque
     dates concaténées (c'est donc une image à 50 bandes). 

     Rejouer l'ensemble du TP avec cette image de 50 bandes. Quel est
     l'apport de la série multi-temporel pour la performance de
     classification ?

     Comparez dans Qgis les deux cartes de classification régularisées.

**** Pour aller plus loin

     1) Peut on obtenir de meilleure performance avec d'autres
        algorithmes de classification ?
     
     2) A l'aide de Qgis, fusionner dans la donnée de référence les
        classes pelouse et lande ligneuse. Quelle performance obtenez
        vous ?

     3) L'application ~TrainImagesClassifier~ contient également un
        algorithme de classification non-supervisée (Shark
        KMeans). Comparer le résultat d'une classification supervisée
        et non-supervisée avec la même image. 

** Classification supervisée pour les séries multi-temporelles    :solutions:

Dans la correction suivante, la variable d'environnement ~$DATA~
correspond au répertoire contenant les données du TP ~TODO~.

*** Réaliser un apprentissage mono-date

L'apprentissage mono-date se réalise avec la commande suivante :

#+BEGIN_EXAMPLE
$ otbcli_TrainImagesClassifier -io.il $DATA/images/20160607_T31TCJ_ROI_20m.tif \
                               -io.vd $DATA/references/training/training.shp   \
                               -io.out model.rf                                \
                               -sample.vfn CODE -classifier rf                 \
                               -classifier.rf.nbtrees 50 -classifier.rf.max 20 \
                               -classifier.rf.cat 13
#+END_EXAMPLE

Cette première exécution donne les résultats suivants :
#+LATEX: \begin{small}
#+BEGIN_EXAMPLE
Confusion matrix (rows = reference labels, columns = produced labels):
       [10]  [31]  [32]  [34]  [36]  [41]  [42 ] [43]  [44]  [51] [211] [221] [222] 
[ 10]   374     3     0    26     1     6    19    11     2     0    13    10    13 
[ 31]     0   436     5     7    14     0     0     0     0     0     7     8     1 
[ 32]     3    16   420     6    15     0     0     0     0     0    12     3     3 
[ 34]    30    16    21   268    41     1    13     2     1     0    27    18    40 
[ 36]    10     6    13    31   336     0     7     0     0     0    42    13    20 
[ 41]     5     0     0     0     0   388    49    21    13     0     0     1     1 
[ 42]    31     1     3    10     3    44   288    36    22     0     0     5    35 
[ 43]    18     0     2    11     1    37    59   227   114     1     0     7     1 
[ 44]     7     0     3     3     2     5    10    71   371     0     0     5     1 
[ 51]     0     0     6     0     0     0     0     0     1   470     0     1     0 
[211]    19     7    13    41    64     0     3     0     0     0   266    14    51 
[221]    18    18     8    13    23     1    11     4     3     0    38   332     9 
[222]    22     0     1    30    12     0    14     0     0     0    16     4   379

[...]

Global performance, Kappa index: 0.710774

#+END_EXAMPLE
#+Latex: \end{small}

Ces performances sont cependant très optimistes, car les échantillons
utilisés pour les estimer proviennent des mêmes polygones. Pour
obtenir une évaluation plus réaliste des performances, il faut
utiliser un jeu de validation différent :

#+BEGIN_EXAMPLE
$ otbcli_TrainImagesClassifier -io.il $DATA/images/20160607_T31TCJ_ROI_20m.tif \
                               -io.vd $DATA/references/training/training.shp   \
                               -io.valid $DATA/references/testing/testing.shp  \
                               -io.out model.rf                                \
                               -sample.vfn CODE -classifier rf                 \
                               -classifier.rf.nbtrees 50 -classifier.rf.max 20 \
                               -classifier.rf.cat 13
#+END_EXAMPLE

Ce qui donne les résultats suivants :

#+LATEX: \begin{small}
#+BEGIN_EXAMPLE
Confusion matrix (rows = reference labels, columns = produced labels):
       [10]  [31]  [32]  [34]  [36]  [41]  [42]  [43]  [44]  [51] [211] [221] [222] 
[ 10]   795     6     6    47     9     4    13    18     0     0    22    10    23 
[ 31]     1   777    38    14    42     0     0     0     0     1    59    21     0 
[ 32]     1    34   865     3    12     2    14     1     1     0     2    15     3 
[ 34]    50   273   120    72    51     0     8     0     0    49   105   157    68 
[ 36]    23    27    45   186   336     0     1     1     0     0   215    79    40 
[ 41]     4     0     1     1     0   665   176    53    49     0     1     1     2 
[ 42]    20     1     3    11     2    98   652    75    43     0     5     8    35 
[ 43]    21     0     1    19     5    44   207   464   146     1     8    17    20 
[ 44]     7     0     1     3     0    13    23   240   662     0     0     4     0 
[ 51]     0     0     1     0     0     0     0     3     1   945     0     3     0 
[211]    81    21    17    81   112     1    16     4     0     0   507    40    73 
[221]    46    51    22    43    42     0    18    10     2     2   107   541    69 
[222]    70     0     0    68    23     0    71     1     0     0    45    11   664

[...]

Global performance, Kappa index: 0.611403
#+END_EXAMPLE
#+Latex: \end{small}

Si l'on désactive l'option ~cleanup~ en ajoutant le paramètre ~-cleanup
0~, l'application n'efface pas les sorties intermédiaires générées.

Les fichiers XML suivants contiennent les statistiques de nombre
d'échantillons disponibles par classe pour le jeu d'apprentissage et
celui de validation.
- ~model.rf_statsTrain_1.xml~
- ~model.rf_statsValid_1.xml~

Les fichiers Shapefile suivants contiennent les échantillons utilisés
pour l'apprentissage et pour la validation:
- ~model.rf_samplesTrain_1.shp~
- ~model.rf_samplesValid_1.shp~

Ces fichiers contiennent des points correspondant aux échantillons
sélectionnés dans les polygones d'apprentissage. Chaque point contient
un ensemble de primitives qui correspond aux radiométries mesurées à
cet endroit dans l'image. Ces deux fichiers peuvent être affichés dans
Qgis.

*** Identifier la date la plus performante


La commande suivante permet de réaliser l'apprentissage pour chaque
date. 

#+BEGIN_EXAMPLE
$ for f in $DATA/images/*.tif; do echo $f;            \
      otbcli_TrainImagesClassifier -io.il $f          \
      -io.vd $DATA/references/training/training.shp   \
      -io.valid $DATA/references/testing/testing.shp  \
      -sample.vfn CODE -classifier rf                 \
      -classifier.rf.nbtrees 50 -classifier.rf.max 20 \
      -classifier.rf.cat 13 -io.out model.rf   | grep Kappa; done
#+END_EXAMPLE

Les coefficients Kappa par date généré par cette commande sont les
suivants :

|------------+----------|
|       Date |    Kappa |
|------------+----------|
| 2016-06-07 | 0.609741 |
| 2016-07-07 | 0.615163 |
| 2016-08-06 | 0.593739 |
| 2016-09-05 | 0.614463 |
| 2016-10-05 | 0.628716 |
|------------+----------|

On constate que ce coefficient ne varie pas beaucoup, mais que la date
du ~2016-10-05~ obtient des performances légèrement meilleures.

*** Réaliser la classification et produire une carte en couleur

Pour réaliser la classification, on prend le fichier ~model.rf~ appris
sur la date ~2016-10-05~, et on utilise la commande suivante :

#+BEGIN_EXAMPLE
$ otbcli_ImageClassifier -in $DATA/images/20161005_T31TCJ_ROI_20m.tif \
                         -out classif_20161005.tif uint8              \
                         -model model.rf
#+END_EXAMPLE

L'image ~classif_20161005.tif~ contient pour chaque pixel le code de
la classe qui lui a été attribué. Afin de faciliter la lisibilité de
l'image, on peut transformer celle-ci en attribuant une couleur
différente à chaque classe en utilisant l'application de
*ColorMapping*:

#+BEGIN_EXAMPLE
$ otbcli_ColorMapping -in classif_20161005.tif            \
                      -out classif_20161005_rgb.tif uint8 \
                      -method custom -method.custom.lut   \ 
                      $DATA/support/color_map.txt
#+END_EXAMPLE

Une autre manière de visualiser l'image ~classif_20161005.tif~ est de
l'ouvrir dans QGis et d'utiliser le fichier de style fournit dans
~support/classif.qml~.

*** Évaluer la performance globale

 Pour évaluer les performances sur l'ensemble de la donnée de
 validation, on utilise l'application *ComputeConfusionMatrix*. Cette
 application complète l'évaluation réalisée lors de l'apprentissage,
 et permet d'évaluer la performance d'une carte de classification qui
 a éventuellement été retraitée. Attention à ne pas utiliser en entrée
 la carte colorisée créée à l'étape précédente, qui n'est utile qu'à
 des fins de visualisation et de publication.
 
 
 #+BEGIN_EXAMPLE
 $ otbcli_ComputeConfusionMatrix -in classif_20161005.tif -ref vector  \
                   -ref.vector.in $DATA/references/testing/testing.shp \
                                 -out confusion_20161005.csv           \
                                 -ref.vector.field CODE
#+END_EXAMPLE

La performance est évaluée en utilisant l'ensemble des données
disponibles dans le jeu de validation. Voici le résultat :

#+LATEX: \begin{small}
#+BEGIN_EXAMPLE
Confusion matrix (rows = reference labels, columns = produced labels):
       [  10] [  31] [  32] [  34] [  36] [  41] [  42] [  43] [  44] [  51] [ 211] [ 221] [ 222] 
[  10] 111624     63   2061  11263   4156   2487   1958   1297    398     34   8497   3068   3666 
[  31]     12   9568    433    132    277      0     17      0      0      0     21    331    471 
[  32]      0     35   1003      7      7      2      8      2      5      1      0     42      7 
[  34]     93    312    278    257    136     11     73      8      8     68    216    209    248 
[  36]     26     73     45    125    454      0      6      0      0      0    158     25     41 
[  41]     46      0     19     27      9   3842    856    371    351      3      7     23     73 
[  42]    973      9    132    778    318   5624  31345   3136   2645     12    501    535   3412 
[  43]   1185     14    185    617    199   2002   7324  16246   7308    109    231    330   1164 
[  44]     33      0      1     11      0     30    121    820   2361     11      0     42     14 
[  51]     68      7    117      3     33      3     18    138    180  22628     11    178     17 
[ 211]    899     72     67   1429   1284     42     34     13      0      0   6396    157    360 
[ 221]    339    748    507    141    442     10    302     53     95     47    501   8495    641 
[ 222]    151      1     26    191    217     10    406     18      7      1    407    119   2704

[...]

Kappa index: 0.608824
#+END_EXAMPLE
#+Latex: \end{small}

 
*** Régulariser et mesurer le gain de performance

*** Réaliser une classification multi-date et mesurer le gain de performance
