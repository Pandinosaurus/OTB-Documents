** Supervised classification of a satellite image time series	   :slides:
*** Goals and data
**** Goals
     - Understand the applications needed for the supervised classification
       procedure
     - Measure the quality of classification results
     - Know the available post processing steps
**** Data
     The data are available in the ~Data/classification~ directory, with the
     following sub directories:
     - ~Extract16bits~: the Landsat-8 time series,
     - ~training~: the training data in the /shp/ format,
     - ~testing~ the testing data in the /shp/ format.

*** Planning
    Planning for this workshop:
    1. Introduction to the Landsat-8 data set
    2. Data preparation
    3. Available sample statistics computation
    4. Sample position selection
    5. Feature extraction for the samples
    6. Model training
    7. Classification
    8. Post-processing
    9. Complete performance evaluation
    10. Color map production

*** Introduction to the Landsat-8 data set

    *Spatial resolution:* 30 meters

**** Dates :BMCOL:B_block:
     :PROPERTIES:
     :BEAMER_col: 0.5
     :BEAMER_env: block
     :END:

|------------|
| 2014-03-09 |
| 2014-04-01 |
| 2014-04-17 |
| 2014-05-28 |
| 2014-06-20 |
| 2014-07-31 |
| 2014-09-01 |
| 2014-10-03 |
| 2014-10-26 |
|------------|

**** Bands :BMCOL:B_block:
     :PROPERTIES:
     :BEAMER_col: 0.5
     :BEAMER_env: block
     :END:

 |---+---------------------|
 | 0 | Coastal aerosol     |
 | 1 | Blue                |
 | 2 | Green               |
 | 3 | Red                 |
 | 4 | Near Infrared (NIR) |
 | 5 | SWIR 1              |
 | 6 | SWIR 2              |
 |---+---------------------|

*** Introdution to the training and testing data

|------+-----------------------+-----------|
| Code | Name                  | #polygons |
|------+-----------------------+-----------|
|   11 | Summer crops          |      7898 |
|   12 | Winter crops          |      8171 |
|   31 | Deciduous forests     |       867 |
|   32 | Evergreen forests     |       125 |
|   34 | Cultivated grasslands |        45 |
|   36 | Woody moorlands       |       386 |
|   41 | Built-up              |      4719 |
|   51 | Water                 |      1280 |
|  211 | Natural grasslands    |      5647 |
|  221 | Orchards              |       204 |
|  222 | Vineyards             |       559 |
|------+-----------------------+-----------|

*** Supervised classification
    #+ATTR_LATEX: :float t :width \textwidth
    [[file:Images/classification.png]]

*** RF algorithm
    A committee of random decision trees.

**** Learning
     1. Split the learning set in k random sets $S_k$
     2. For each $S_k$, randomly choose $F_k$ features
     3. Recursively build a decision tree, for each node:
        1. Choose $f \in F_k$ and the threshold $t_k$ which partitions the remaining set in two subsets as pure as possible
        2. Stop when the remaining set is too small

**** Decision
     Majority vote between all random trees


*** Confusion matrix


|-----------+--------------+--------------+--------------+
|           | Pred. 1      | Pred. 2      | Pred. 3      |
|-----------+--------------+--------------+--------------+
| Ref. 1    | True pos. 1  |              |              |
| Ref. 2    |              | True pos. 2  |              |
| Ref. 3    |              |              | True pos. 3  |
|-----------+--------------+--------------+--------------+

- $precision = \frac{VP i}{\sum pred. i}$
- $recall = \frac{VP i}{T\sum ref. i}$
- $accuracy = \frac{\sum{VP i}}{Total}$
- $Kappa = \frac{Accuracy - chance}{1-chance}$


** Supervised classification of a satellite image time series	    :guide:
*** Description                                                        :desc:
**** Summary

     This exercise allows to get familiar with supervised, pixel-wise
     classification applications in Orfeo ToolBox, using a Sentinel-2
     time serie and a reference dataset for supervision.

**** PrÃ©-requisites
     
     - Software installed (Monteverdi and Orfeo ToolBox)
     - Data downloaded
     - Basic knowledge on using applications in OTB
     - Basic knowledge on supervised classifcation
     
**** Objectives

     Objectives are the following:
     - Knowing the different applications of the supervised classification process
     - Using different learning algorithms
     - Measuring classification performances
     - Post-processing of classification

*** Steps                                                             :steps:

    Data are available in the ~Data/classification~ folder, with following sub-folders:
    - ~images~ contains the Sentinel-2 time serie,
    - ~references/training~ contains training data in /shp/ format,
    - ~references/testing~ contains testing data in /shp/ format

**** Introduction to Sentinel-2 data
     
     In the data package, folder ~Data/classification/images~ cotains
     5 Sentinel-2 images, extracted on tile T31TCJ, at the following dates:
    
|------------|
| 2016-06-07 |
| 2016-07-07 |
| 2016-08-06 |
| 2016-09-05 |
| 2016-10-05 |
|------------|


    Those images are multispectral, with 10 bands resampled at 20 m:

|---+----------------+------------+------------+--------------------|
| # | Band name      | S2 band id | Wavelength | Initial resolution |
|---+----------------+------------+------------+--------------------|
| 0 | Blue           | B2         | 490 nm     | 10 m               |
| 1 | Green          | B3         | 560 nm     | 10 m               |
| 2 | Red            | B4         | 665 nm     | 10 m               |
| 3 | NIR - Narrow 1 | B5         | 705 nm     | 20 m               |
| 4 | NIR - Narrow 2 | B6         | 740 nm     | 20 m               |
| 5 | NIR - Narrow 3 | B7         | 783 nm     | 20 m               |
| 6 | NIR - Wide     | B8         | 842 nm     | 10 m               |
| 7 | NIR - Narrow 4 | B8A        | 865 nm     | 20 m               |
| 8 | SWIR 1         | B11        | 1610 nm    | 20 m               |
| 9 | SWIR 2         | B12        | 2190 nm    | 20 m               |
|---+----------------+------------+------------+--------------------|


We therefore have 50 bands for each pixels. Images are encoded over 16 bits.

Open one image in monteverdi and set the bands for a true color
display (red, green, blue)

Open the remaining four images and look for changes.

*Note:* Le fichier de style ~support/images.qml~ can be loaded into
Qgis to set the rendering and color channls for each image.

Files ~references/training/training.shp~ 
and
~references/testing/testing.shp~ contain polygons defining 13 classes
over the scene:

|------+-----------------------------+---------------------+--------------------|
| Code | Name                        | #polygones training | #polygones testing |
|------+-----------------------------+---------------------+--------------------|
|   10 | Annual crops                | 3129                | 3078               |
|   31 | Deciduous Forests           | 176                 | 292                |
|   32 | Evergreen Forests           | 23                  | 29                 |
|   34 | Grass                       | 2                   | 2                  |
|   36 | Woody Moorlands             | 63                  | 38                 |
|   41 | Dense Urban Area            | 30                  | 33                 |
|   42 | Light Urban Area            | 326                 | 239                |
|   43 | Industrial Area             | 154                 | 212                |
|   44 | Roads                       | 162                 | 114                |
|   51 | Water                       | 243                 | 332                |
|  211 | Meadow                      | 320                 | 311                |
|  221 | Orchards                    | 227                 | 254                |
|  222 | Vineyards                   | 129                 | 97                 |
|------+-----------------------------+---------------------+--------------------|

Open one of the files in QGis. The attribute table can be accessed by
    right-clicking on the layer -> /Open attributes table/. Each label
    is visible, and the list can be filtered with SQL expressions.

    *Note :* There is a style file ~support/polygons.qml~ that can be
    loaded into Qgis to colorize polygons according to their classes.
    
    Polygons are splitted into two sets: training and validation.

**** Single date training
     
     We are going to use th *TraingImagesClassifier* application in
     order to do supervised learning from the training date in
     ~references/training/training.shp~. First, we are going to work
     with the image from the 07.06.2016.

     The *TraingImagesClassifier* application will sample some image
     pixels within the training polygons, in order to build a
     well-balanced training set. This set is then passed to the
     learning algorithm.
     
     This application has some mandatory parameters:
     - The input images, which bands will be used as features by the
       learning algorithm,
     - The vector layer containing references polygons,
     - The name of the field in that layer that contains the class
       identifier,
     - The output file containing the learnt model (call it ~model.rf~).

     Some optional parameters should also be set as follows:
     - Random forest classifier for the learning algorithm,
     - The number of tree set to 50,
     - The maximal tree depth to 20,
     - The minimum number of samples in each node to 70,
     - The number of clusters to 13 (equal to the number of classes)

     Look at the application logs, in particular the confusion matrix,
     the Kappa coefficients, and scores per class. What do you think
     of those results ? Without using polygons dedicated to
     validation, the application will use a part of the generated
     samples for validation. What can be deduced regarding the
     displayed performances ?

     Do the training again, but this time also use the validation
     dataset in ~reference/testing/testing.shp~ as validation layer
     (you therefore set two differents shp files in the
     application). What can be observed ?
     
     Do the training again, and deactivate the ~cleanup~ option. Look
     at the intermediate data that have been generated. What are they
     used for ?

**** Spot the date with the best performances
     
     Do the training again, this time for each image date. What is
     the date with the best performances ? Does the Kappa coefficient
     change a lot ?
     
     Keep the ~model.rf~ file corresponding to the best date.

**** Classifying and producing a colored classification map

     Use the *ImageClassifier* application to produce the
     classification map corresponding ot the best date (the one from
     05.09.2016). Be careful to use the model file training with this date.
     
     The output map is a tif image where each pixel value corresponds
     to the class. To visualize such images, the *ColorMapping*
     application allows to set a given color for each class.

     Use the *custom* mode from the *ColorMapping* application with
     the lookup table in ~support/color_map.txt~ to produced the
     colored map.
     
     *Note :* The image may not display correctly in QGis, because of
     default no data value set in the file. No data can be deactivated
     in Qgis layer properties dialog.
     
**** Evaluate global performances

     We are now going to use the *ComputeConfusionMatrix* application
     in order to compute global classification performances. With
     respect to the performance evaluation during the training step,
     this application allows to:
     - Take into account all pixels in the reference date,
     - Evaluate performances of a post-processed classification map
       (for instance with regularisation).
     The ~ref.vector.field CODE~ parameter is mandatory to indicate
    the field corresponding to class ids.

    Copute the global performance of the classification. What do you
    observe with respect to the performance computed during training ?
    How to explain this phenomena ?
     
**** Classification regularization
     
     We are now going to use the *ClassificationMapRegularization*
     application. It filters the classification map using a local
     majority voting scheme.

     Parameters are:$
     
     - ip.radius 1 :: Radius of the voting zone
     - ip.suvbool 0 :: What to do in case of tie vote. 0 is to keep
                       the initial value.

     Filter the result of previous classification. Evaluate the
     performances of the filtered map. What do you observe ?
      
**** RÃ©aliser une classification multi-date et mesurer le gain de performance

     We are now going to use all dates for classifications. For this,
     you can use the ~images/all.vrt~ which contains all bands from
     each date contatenated (the image has therefore 50 bands).
     
     Do the whole workshop, but this time with this 50 bands
     image. What do temporel series bring to the performance of
     classification ?

     Compare both results in QGis.

**** Going further
     
     1) Can we obtain better perforamnces with other classification
        algorithms ?

     2) In Qgis, merge in reference data the grass and Woody
        Moorlands. Are the performances better ?

     3) The ~TrainImagesClassifier~ also has an unsupervised algorithm
        (Shark KMeans). Compare results with supervised and
        unsupervised classification.

** Supervised classification of a satellite image time series    :solutions:

*Note :* In this solution, the environment variable ~${LS8DATA}~ contains the path the the /classification/ folder containing the data for the exercises.

*** Data preparation

    First of all, we concatenate all the bands for all the dates:

    #+BEGIN_EXAMPLE
    $ otbcli_ConcatenateImages -il ${LS8DATA}/LANDSAT_*.tif -out alldates.tif uint16
    #+END_EXAMPLE

    Then, we compute the NDVI for each date:
    
    #+BEGIN_EXAMPLE
    $ cd ${LS8DATA}
    $ for f in LANDSAT_*.tif; do \
        otbcli_RadiometricIndices -channels.blue 2 -channels.green 3 \
                                  -channels.red 4 -channels.nir 5    \
                                  -in "$f" -out "NDVI_$f" -list Vegetation:NDVI; done
    #+END_EXAMPLE

    We can then create the NDVI time series:

    #+BEGIN_EXAMPLE
    $ otbcli_ConcatenateImages -il ${LS8DATA}/NDVI_*.tif -out ndvis.tif
    #+END_EXAMPLE

    And the image containing all the bands and the NDVI time series:

    #+BEGIN_EXAMPLE
    $ otbcli_ConcatenateImages -il alldates.tif ndvis.tif -out all.tif
    #+END_EXAMPLE
    
*** Available sample statistics computation

    Computing the avalilable sample statistics can be done as follows:

    #+BEGIN_EXAMPLE
    $ otbcli_PolygonClassStatistics -in Extract16bits/alldates.tif \
                                    -field CODE -vec training/training.shp \
                                    -out training_stats.xml

    $ otbcli_PolygonClassStatistics -in Extract16bits/alldates.tif \
                                    -field CODE -vec testing/testing.shp \
                                     -out testing_stats.xml
    #+END_EXAMPLE

    In the ~training_stats.xml~ and ~validation_stats.xml~ files, one can find the following information:

    In ~training_stats.xml~:

    #+BEGIN_EXAMPLE
    <Statistic name="samplesPerClass">
        <StatisticMap key="11" value="56774" />
        <StatisticMap key="12" value="59347" />
        <StatisticMap key="211" value="25317" />
        <StatisticMap key="221" value="2087" />
        <StatisticMap key="222" value="2080" />
        <StatisticMap key="31" value="8149" />
        <StatisticMap key="32" value="1029" />
        <StatisticMap key="34" value="3770" />
        <StatisticMap key="36" value="941" />
        <StatisticMap key="41" value="2630" />
        <StatisticMap key="51" value="11221" />
    </Statistic>
    #+END_EXAMPLE

    The class /natural grasslands/ (label 211) has 25 317 samples. One can also notice that the training sample has 173 345 samples, and that the /woody moorlands/ class (label 36) is the one with fewer samples with only 941 samples.

    The polygon with id 1081 in the training set has 342 samples:

    #+BEGIN_EXAMPLE
    <StatisticMap key="1081" value="342" />
    #+END_EXAMPLE

    In ~testing_stats.xml~:

    #+BEGIN_EXAMPLE
    <Statistic name="samplesPerClass">
        <StatisticMap key="11" value="134590" />
        <StatisticMap key="12" value="127548" />
        <StatisticMap key="211" value="59052" />
        <StatisticMap key="221" value="4820" />
        <StatisticMap key="222" value="6393" />
        <StatisticMap key="31" value="18620" />
        <StatisticMap key="32" value="2121" />
        <StatisticMap key="34" value="9351" />
        <StatisticMap key="36" value="2812" />
        <StatisticMap key="41" value="6110" />
        <StatisticMap key="51" value="28858" />
    </Statistic>
    #+END_EXAMPLE

    The /natural grasslands/ class (label 211) has 59 052 samples.

*** Sample position selection

    The application documentaion shows that the different strategies for the sampling are:
    - byclass :: the number of sample for each class can be set using a file
    - constant :: for choosing a constant number of samples for all classes
    - smallest :: select for all classes the number of samples of the
         class which has the smallest amount
    - all :: take all samples.

 
    To perform the sample selection using the /smallest/ strategy, on
    can do:

    #+BEGIN_EXAMPLE
    $ otbcli_SampleSelection -in alldates.tif -field CODE \
                             -vec training/training.shp   \
                             -out training_samples.sqlite \
                             -instats training_stats.xml -strategy smallest
    #+END_EXAMPLE

  Here is the result of the sample estraction (data extracted from the
  logs):
    
  |-----------+-----------------+--------------+-----------|
  | className | requiredSamples | totalSamples |      rate |
  |-----------+-----------------+--------------+-----------|
  |        11 |             941 |        56774 | 0.0165745 |
  |        12 |             941 |        59347 | 0.0158559 |
  |       211 |             941 |        25317 | 0.0371687 |
  |       221 |             941 |         2087 |  0.450886 |
  |       222 |             941 |         2080 |  0.452404 |
  |        31 |             941 |         8149 |  0.115474 |
  |        32 |             941 |         1029 |   0.91448 |
  |        34 |             941 |         3770 |  0.249602 |
  |        36 |             941 |          941 |         1 |
  |        41 |             941 |         2630 |  0.357795 |
  |        51 |             941 |        11221 | 0.0838606 |
  |-----------+-----------------+--------------+-----------|

  In total, 10 351 samples have been selected. If one loads the layer
  in QGIS, the selected positions can be displayed.
  
  #+ATTR_LATEX: :width 0.9\textwidth
  [[file:Images/samples_selection.png]]

  The attributes associated to each point are those who were present in the original file ~training.shp~, and the  ~originfid~ attribute which corresponds to the polygon identifier of from which the sample has been taken.

*** Feature extraction for the samples

    To compute the features associated to each sample, one proceeds as follows. For the image bands:

    #+BEGIN_EXAMPLE
    $ otbcli_SampleExtraction -in alldates.tif               \
                              -vec training_samples.sqlite   \
                              -outfield prefix               \
                              -outfield.prefix.name band_    \
                              -field code 

    $ otbcli_SampleExtraction -in ndvis.tif                  \
                              -vec training_samples.sqlite   \
                              -outfield prefix               \
                              -outfield.prefix.name ndvi_    \
                              -field code 
    #+END_EXAMPLE

    Same approach for the validation set:

    #+BEGIN_EXAMPLE
    $ otbcli_SampleExtraction -in alldates.tif               \
                              -vec testing_samples.sqlite   \
                              -outfield prefix               \
                              -outfield.prefix.name band_    \
                              -field code 

    $ otbcli_SampleExtraction -in ndvis.tif                  \
                              -vec testing_samples.sqlite   \
                              -outfield prefix               \
                              -outfield.prefix.name ndvi_    \
                              -field code 
    #+END_EXAMPLE

*** Model training

    In this section, we will use the shell variables proposed in the question.

    The training is done as follows:
    
    #+BEGIN_EXAMPLE
    $ otbcli_TrainVectorClassifier -io.vd training_samples.sqlite \
                                   -cfield code -classifier rf    \
                                   -classifier.rf.max 20          \
                                   -io.out model.rf -feat ${date1}
    #+END_EXAMPLE

    This first run yields the following results:

    #+BEGIN_EXAMPLE
    Confusion matrix (rows = reference labels, columns = produced labels):
      [11] [12] [31] [32] [34] [36] [41] [51] [211] [221] [222] 
[ 11]   861    28     2     0     8     5     3     0     5     6    24 
[ 12]    16   889     3     1     3     2     1     2     5    12     7 
[ 31]     8    10   873     5     9    19     2     0     6     9     0 
[ 32]     4     0    21   895     6     3     2     3     1     4     2 
[ 34]    12    20    39     9   785    19     8     1    19    17    12 
[ 36]    10    30    46    11    21   771     8     1    20     9    14 
[ 41]     4    13     8     4     5     1   862     3    16    17     8 
[ 51]     2    11     2     0     4     2     5   906     2     7     0 
[211]     2    27    35     5    21    32     2     1   782    15    19 
[221]    13    14     5     3     7     4     8     6    11   845    25 
[222]    15    24     2     0     2     8     0     0    16    14   860 

[...]

Global performance, Kappa index: 0.891296 
    #+END_EXAMPLE
    
    The reason why the Kappa coefficient is so high despite the use of
    a single date, is that when no validation set is given, the
    application measures the performances using the training set. In
    order to get a more realistic evaluation, one can validate using
    the file ~testing_samples.sqlite~ that we created before:

    #+BEGIN_EXAMPLE
    $ otbcli_TrainVectorClassifier -io.vd training_samples.sqlite   \
                                   -valid.vd testing_samples.sqlite \
                                   -cfield code -classifier rf      \
                                   -classifier.rf.max 20            \
                                   -io.out model.rf -feat ${date1}
    #+END_EXAMPLE
    

    In this case, the results are the following:

    
    #+BEGIN_EXAMPLE
     [11] [12] [31] [32] [34] [36] [41] [51] [211] [221] [222] 
[ 11]  1504   285     9     1    32    40    43     3    43    36   126 
[ 12]   183  1619    13     8    15    25     9     5    59    77   108 
[ 31]    26    60  1463    89    76   237    38    30    33    65     4 
[ 32]    47    54   362  1478    49    31    23    16    26    29     6 
[ 34]    45    45   364   230   252   620    21    19   270   110   145 
[ 36]    85   164   232    65   421   647    27     6   214   135   125 
[ 41]    49    79    51    32    49    20  1559    29    61   128    64 
[ 51]    27    39    26    17     7    19    44  1919     6    17     0 
[211]    21   131   113    29   274   143    11     6  1086    66   241 
[221]    93   165   113    93   201   148    95    12   196   771   234 
[222]   164   229     8     4    91    58    10     1   181   123  1252

[...]

Global performance, Kappa index: 0.538822
#+END_EXAMPLE

These results show poor performances using a single date.

In order to test different configurations, one can use the variables
suggested in the question and pass them as the ~-feat~ parameter. For
instance, to test the first 2 dates, one can use ~-feat ${date1} ${date2}~.

**** Which date yields the best single date performances?

The best date is the third one (2014-04-17), with a Kappa coefficient of 0.578.

|------------+----------|
|       Date |    Kappa |
|------------+----------|
| 2014-03-09 | 0.538822 |
| 2014-04-01 | 0.560085 |
| 2014-04-17 | 0.578801 |
| 2014-05-28 |  0.56494 |
| 2014-06-20 | 0.560509 |
| 2014-07-31 | 0.540943 |
| 2014-09-01 | 0.555276 |
| 2014-10-03 | 0.530006 |
| 2014-10-26 | 0.494788 |
|------------+----------|

This table has been obtained with the following bash script:

#+BEGIN_EXAMPLE
$ for i in $(seq 1 9); do var=date$i; otbcli_TrainVectorClassifier    \
                                     -io.vd training_samples.sqlite   \
                                     -valid.vd testing_samples.sqlite \
                                     -cfield code -classifier rf      \
                                     -classifier.rf.max 20            \
                                     -io.out model.rf -feat ${!var}   \
                                     | grep Kappa; done
#+END_EXAMPLE

**** Has the coastal blue band an interest for the classification?intÃ©rÃªt pour la classification ?

     Using the parameter ~-feat ${date1}~ one gets a Kappa coefficient
     of 0.538822 for the first date, while if one removes the coastal
     blue band using ~-feat ${date1_nocb}~ the Kappa coefficient is
     0.538068. One can therefore conclude that this band contains
     little information for this classification problem.

**** Which are the performances using all the spectral bands?toutes les bandes spectrales ?
     
     Using the parameter ~-feat ${dates}~, one gets a Kappa coefficient of 0.677147.

**** What are the performances using the NDVI time series alone?

     Using the parameter ~-feat ${ndvis}~ one gets a Kappa coefficient
     of 0.554286. Using only these 9 values, the performances are only
     0.12 below the case using 63 spectral bands. The results are also
     better than some individual dates for which 7 bands are used.

**** What are the performances using all the spectral bands and the NDVI time series?

     Using the parameter ~-feat ${bands} ${ndvis}~ one gets a Kappa
     coefficient of 0.682333, which is slightly better than the
     spectral bands alone.

**** In the latter case, analyse the performances for each class.

     The /water/ class (label 51) is the best classified, with an
     F-score of 0.945575.

     The /cultivated grasslands/ (label 34) and /woody moorlands/ (label 36)
     are the worse recognised with F-scores of 0.278807 and 0.428884 respectively. All other classes have F-scores sometimes way above 0.6.

     If we analyse more precisely the confusion matrix, one can see that these 2 classes are often confused with one another by the model: 24% of the /natural grasslands/ samples are classified as /woody moorland/ (and 17% as /cultivated grasslands/), while 22% of /woody moorland/ samples are classified as /natural grasslands/ (and 10% as /cultivated grasslands/).

*** Classification

    To produce the classification map, we use the model trained on all
    the spectral bands and the NDVI time series (in this order). Pour
    rÃ©aliser la carte de classification, on va utiliser le modÃ¨le
    appris sur l'ensemble des bandes spectrales et du profil de NDVI
    (dans cet ordre). Warning: the model has to be trained with the
    same feature order as the one used by the *ImageClassifier*
    application.

    #+BEGIN_EXAMPLE
    $ otbcli_ImageClassifier -in Extract16bits/all.tif \
                             -out classif.tif uint8 \
                             -model model.rf
    #+END_EXAMPLE

*** Post-processing

    To regularise the classification map, one can use the following
    command:

    #+BEGIN_EXAMPLE
    $ otbcli_ClassificationMapRegularization -ip.radius 1 -ip.suvbool 0    \
                                             -io.in classif.tif            \
                                             -io.out classif_reg.tif uint8 
    #+END_EXAMPLE

    It is straighforward to see the effect of the regularisation by
    displaying the result in QGIS (beware of unchecking the no data
    values in QGIS), but it is also interesting to evaluate the impact
    of this operation on the classification perfomances. We will
    address this issue in the following section.

*** Complete performance evaluation

    To evaluate the performances over the whole validation set, we use
    the *ComputeConfusionMatrix* application.

    On the raw classification map:

    #+BEGIN_EXAMPLE
    $ otbcli_ComputeConfusionMatrix -in classif.tif -ref vector        \
                                    -ref.vector.in testing/testing.shp \
                                    -out confusion.csv                 \
                                    -ref.vector.field CODE
    #+END_EXAMPLE

    This complete evaluation yields a Kappa coefficient of 0.803679.
    This value is way higher than the one obtained during the training
    phase which was only 0.682333. This is explained by the fact that
    the validation data used during the training step was generated
    using the /smallest/ strategy, which produces the same number of
    samples for each class. However, if we look at the statistics
    generated at the beginning of the workshop, one can see that
    /summer crops/ (11), /winter crops/ (12) and /water/ (51) are
    over-represented in the reference data. These 3 classes are the
    ones having the best performances in the classification. Therfore,
    their outnumbering produces higher classification scores. If we
    had generated the validation file using the /all/ strategy, we
    would have obtained similar prerformances during the training
    step. However, this would have hidden the poor performanced for
    some classes.

    On the regularised classification map:

    #+BEGIN_EXAMPLE
    $ otbcli_ComputeConfusionMatrix -in classif_reg.tif -ref vector    \
                                    -ref.vector.in testing/testing.shp \
                                    -out confusion.csv                 \
                                    -ref.vector.field CODE
    #+END_EXAMPLE

    Now the Kappa coefficient is 0.873691. The regularisation improves
    the performances, since the final result is more similar to the
    reference data which contains homogeneous polygons.

*** Color map production
    
    To produce the color map, we use the following command:

    #+BEGIN_EXAMPLE
    $ otbcli_ColorMapping -in classif_reg.tif -out classif_reg_rgb.tif uint8 \
                          -method custom -method.custom.lut color_map.txt
    #+END_EXAMPLE
    
    #+ATTR_LATEX: :width 0.9\textwidth
    [[file:Images/final_classification.png]]


