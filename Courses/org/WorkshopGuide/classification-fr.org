** Classification supervisée pour les séries multi-temporelles       :slides:
*** Objectifs et Données
**** Objectifs
      Les objectifs sont les suivants:
     - Savoir réaliser une classification supervisée
     - Savoir mesurer les performances de la classification
     - Connaître les post-traitements applicables à une classification
**** Données
     Les données sont disponibles dans le répertoire ~Data/classification~, avec les sous-répertoires suivants:
     - ~images~ contient la série multi-temporelle Sentinel2,
     - ~references~ contient la donnée d'apprentissage et de validation au format /shp/,
     - ~support~ contient différents fichiers utiles au TP (fichiers de style Qgis notamment)
     
*** Déroulement
    Les étapes de l'exercice sont les suivantes:
    1. Introduction aux données
    2. Réaliser un apprentissage mono-date
    3. Identifier la date la plus performante
    4. Réaliser la classification et produire une carte en couleur
    5. Évaluer la performance globale
    6. Régulariser et mesurer le gain de performance
    7. Réaliser une classification multi-date et mesurer le gain de performance
       
*** Présentation des données Sentinel-2

    *Résolution spatiale:* 20 mètres (originale: 10 mètres)
    *Tuile:* T31TCJ (extrait)
|------------|
| 2016-06-07 |
| 2016-07-07 |
| 2016-08-06 |
| 2016-09-05 |
| 2016-10-05 |
|------------|

*** Présentation des données Sentinel-2

    *Résolution spatiale:* 20 mètres (originale: 10 mètres)
    *Tuile:* T31TCJ (extrait)

|---+----------------+------------+------------+--------------------|
| # | Band name      | S2 band id | Wavelength | Initial resolution |
|---+----------------+------------+------------+--------------------|
| 0 | Blue           | B2         | 490 nm     | 10 m               |
| 1 | Green          | B3         | 560 nm     | 10 m               |
| 2 | Red            | B4         | 665 nm     | 10 m               |
| 3 | NIR - Narrow 1 | B5         | 705 nm     | 20 m               |
| 4 | NIR - Narrow 2 | B6         | 740 nm     | 20 m               |
| 5 | NIR - Narrow 3 | B7         | 783 nm     | 20 m               |
| 6 | NIR - Wide     | B8         | 842 nm     | 10 m               |
| 7 | NIR - Narrow 4 | B8A        | 865 nm     | 20 m               |
| 8 | SWIR 1         | B11        | 1610 nm    | 20 m               |
| 9 | SWIR 2         | B12        | 2190 nm    | 20 m               |
|---+----------------+------------+------------+--------------------|

*** Présentation des données de référence

|------+-----------------------------+---------------------+--------------------|
| Code | Nom                         | #polygones training | #polygones testing |
|------+-----------------------------+---------------------+--------------------|
|   10 | Cultures annuelles          | 3129                | 3078               |
|   31 | Forêt feuilles caduques     | 176                 | 292                |
|   32 | Forêt feuilles persistantes | 23                  | 29                 |
|   34 | Pelouses                    | 2                   | 2                  |
|   36 | Lande ligneuse              | 63                  | 38                 |
|   41 | Bâti dense                  | 30                  | 33                 |
|   42 | Bâti diffus                 | 326                 | 239                |
|   43 | Zones industrielles         | 154                 | 212                |
|   44 | Routes                      | 162                 | 114                |
|   51 | Eau                         | 243                 | 332                |
|  211 | Prairie                     | 320                 | 311                |
|  221 | Verger                      | 227                 | 254                |
|  222 | Vigne                       | 129                 | 97                 |
|------+-----------------------------+---------------------+--------------------|

*** Classification supervisée
    #+ATTR_LATEX: :float t :width \textwidth
    [[file:Images/classification.png]]
   
*** Algorithme Random Forests (RF)
    Ensemble d'arbres de décision aléatoires

**** Apprentissage
     1. Séparer le jeu d'apprentissage en k ensembles $S_k$ aléatoires
     2. Pour chaque $S_k$ choisir aléatoirement $F_k$ primitives
     3. Construire un arbre de décision récursivement, pour chaque noeud:
        1. Choisir $f \in F_k$ et le seuil $t_k$ qui sépare l'ensemble restant en 2 parties les plus pures
        2. Arrêter quand l'ensemble restant devient trop petit
 
**** Décision
     Vote majoritaire de tous les arbres aléatoires


*** Matrice de confusion


|-----------+--------------+--------------+--------------+
|           | Préd. 1      | Préd. 2      | Préd. 3      | 
|-----------+--------------+--------------+--------------+
| Réf. 1    | Vrais pos. 1 |              |              |
| Réf. 2    |              | Vrais pos. 2 |              |
| Réf. 3    |              |              | Vrais pos. 3 |
|-----------+--------------+--------------+--------------+

- $precision = \frac{VP i}{\sum pred. i}$
- $rappel = \frac{VP i}{T\sum ref. i}$
- $Accuracy = \frac{\sum{VP i}}{Total}$
- $Kappa = \frac{Accuracy - chance}{1-chance}$
  
** Classification supervisée pour les séries multi-temporelles        :guide:
*** Description                                                        :desc:
**** Résumé

     Cet exercice permet de se familiariser avec les applications de
     classification supervisée pixellique de l'Orfeo ToolBox, en
     utilisant une série multi-temporelle Sentinel-2 et un jeu de
     données de référence pour la supervision.

**** Pré-requis
     
     - Logiciels installés (Monteverdi et Orfeo ToolBox)
     - Données téléchargées
     - Connaissance du mécanisme des applications de l'Orfeo ToolBox (voir exercice correspondant)
     - Notions de classification supervisée
     
**** Objectifs

     Les objectifs sont les suivants:
     - Connaître les différentes applications constituant la procédure
       de classification supervisée
     - Utiliser différents algorithmes pour l'apprentissage
     - Savoir mesurer les performances de la classification
     - Connaître les post-traitements applicables à une classification

*** Étapes                                                            :steps:

    Les données sont disponibles dans le répertoire ~Data/classification~, avec les sous-répertoires suivants:
     - ~images~ contient la série multi-temporelle Sentinel-2,
     - ~references/training~ contient la donnée d'apprentissage au format /shp/,
     - ~references/testing~ contient la donnée de validation au format /shp/.

**** Présentation des données Sentinel-2

    Dans l'archive de données, le dossier ~Data/classification/images~ contient 5
    images Sentinel-2, extraites de la tuile T31TCJ, aux dates suivantes:
    
|------------|
| 2016-06-07 |
| 2016-07-07 |
| 2016-08-06 |
| 2016-09-05 |
| 2016-10-05 |
|------------|


    Ces images sont toutes multispectrales avec 10 bandes ré-échantillonnées à 20 m:

|---+----------------+------------+------------+--------------------|
| # | Band name      | S2 band id | Wavelength | Initial resolution |
|---+----------------+------------+------------+--------------------|
| 0 | Blue           | B2         | 490 nm     | 10 m               |
| 1 | Green          | B3         | 560 nm     | 10 m               |
| 2 | Red            | B4         | 665 nm     | 10 m               |
| 3 | NIR - Narrow 1 | B5         | 705 nm     | 20 m               |
| 4 | NIR - Narrow 2 | B6         | 740 nm     | 20 m               |
| 5 | NIR - Narrow 3 | B7         | 783 nm     | 20 m               |
| 6 | NIR - Wide     | B8         | 842 nm     | 10 m               |
| 7 | NIR - Narrow 4 | B8A        | 865 nm     | 20 m               |
| 8 | SWIR 1         | B11        | 1610 nm    | 20 m               |
| 9 | SWIR 2         | B12        | 2190 nm    | 20 m               |
|---+----------------+------------+------------+--------------------|


Au total, c'est donc 50 bandes qui représentent chaque pixel.
Les images sont encodés sur 16 bits.

Ouvrez une image dans monteverdi et régler les bandes pour un affichage en
vrais couleurs (rouge, vert, bleu).

Ouvrez les cinq images et remarquez les changements.

*Note :* Le fichier de style ~support/images.qml~ peut être chargé
dans QGis pour régler la dynamique et la composition colorée de chaque
image à l'identique.

Les fichiers ~references/training/training.shp~ 
et
~references/testing/testing.shp~ contiennent des
polygones qui définissent 13 classes sur l'ensemble de la scène:

|------+-----------------------------+---------------------+--------------------|
| Code | Nom                         | #polygones training | #polygones testing |
|------+-----------------------------+---------------------+--------------------|
|   10 | Cultures annuelles          | 3129                | 3078               |
|   31 | Forêt feuilles caduques     | 176                 | 292                |
|   32 | Forêt feuilles persistantes | 23                  | 29                 |
|   34 | Pelouses                    | 2                   | 2                  |
|   36 | Lande ligneuse              | 63                  | 38                 |
|   41 | Bâti dense                  | 30                  | 33                 |
|   42 | Bâti diffus                 | 326                 | 239                |
|   43 | Zones industrielles         | 154                 | 212                |
|   44 | Routes                      | 162                 | 114                |
|   51 | Eau                         | 243                 | 332                |
|  211 | Prairie                     | 320                 | 311                |
|  221 | Verger                      | 227                 | 254                |
|  222 | Vigne                       | 129                 | 97                 |
|------+-----------------------------+---------------------+--------------------|


    Ouvrez un des fichiers de polygones dans QGIS. La table d'attributs est
    accessible depuis clic-droit sur la couche -> /Ouvrir la table des attributs/.
    Chaque label est visible et la liste est filtrable par expression
    SQL.

    *Note :* Le fichier de style ~support/polygons.qml~ peut être chargé dans
    QGIS pour coloriser les polygones en fonction de leur classe. 

    Les polygones sont répartis en deux ensembles: apprentissage (training) et
    validation (testing).

**** Réaliser un apprentissage mono-date
     
     Nous allons maintenant utiliser l'application
     *TrainImagesClassifier* afin de réaliser l'apprentissage
     supervisé à partir des données d'entraînement disponibles dans
     ~references/training/training.shp~. Pour commencer, nous allons
     réaliser cet apprentissage avec uniquement l'image du 07.06.2016.

     L'application *TrainImageClassifier* va échantillonner certains
     pixels de l'image contenus dans les polygones de la vérité
     terrain, afin de constituer un ensemble d'apprentissage
     équilibré. Celui-ci est ensuite transmis à l'algorithme
     d'apprentissage.

     Cette application prend en paramètres obligatoires:
     - L'image dont les bandes seront utilisées comme descripteurs
       pour l'algorithme de classification,
     - La couche vecteur contenant les polygones de référence,
     - Le nom du champ correspondant à la classe d'occupation du sol
       dans cette couche vecteur,
     - Le fichier sortie ou stocker le modèle appris (on peut
       l'appeler ~model.rf~).

     Régler certains paramètres optionnels comme suit:
     - Le classifieur "Random Forests" pour l'algorithme
       d'apprentissage,
     - Le nombre maximale d'arbres à 50,
     - La profondeur maximale de l'arbre à 20,
     - Le nombre minimum d'échantillons pour chaque noeud à 70,
     - Le nombre de clusters à 13 (équivalent au nombre de classes)

     Examiner les logs de l'application, en particulier la matrice de
     confusion, la valeur du coefficient Kappa et les scores par
     classe. Que constatez-vous ? En l'absence de polygones dédiés à
     la validation, l'application utilise une partie des échantillons
     générés pour la validation. Que peut on en déduire quand aux
     performances affichées ?

     Refaire l'apprentissage, cette fois en utilisant les données de
     validation ~reference/testing/testing.shp~ comme vecteur de
     validation (vous donnez donc à l'application deux fichiers shp
     différents). Que constatez vous ?

     Refaire l'apprentissage, en désactivant l'option
     ~cleanup~. Regardez les données intermédiaires qui ont été
     générées. A quoi correspondent elles ?

**** Identifier la date la plus performante

     Réitérer l'apprentissage pour chacune des dates. Quelle date
     fournit la meilleure performance ? Le coefficient Kappa
     change-t-il beaucoup ?

     Rejouer l'apprentissage correspondant à la meilleure date afin de
     conserver le fichier de modèle ~model.rf~.

**** Réaliser la classification et produire une carte en couleur
     
     Utiliser l'application *ImageClassifier* pour produire la carte
     de classification correspondant à la meilleure date
     (celle du 05.09.2016). Attention à bien utiliser le fichier de modèle
     correspondant entraîné à partir de cette date.

     La sortie de l'étape précédente est une image .tif qui associe à
     chaque pixel une classe. Pour visualiser cette image, l'application
     *ColorMapping* permet d'associer à chaque label une couleur RGB et de
     générer une image de visualisation.  
     
     Utilisez le mode *custom* l'application *ColorMapping* avec la table de couleur fournie
     ~support/color_map.txt~ pour produire une carte colorisée.
     
     # TODO: vérifier si la note suivante est toujours nécessaire ?
     *Note :* Il se peut que l'image ne s'affiche pas correctement dans
     Qgis, du fait d'une valeur non renseignée (no data) par défaut enregistrée dans le
     fichier. La prise en compte du nodata peut être désactivé dans les
     propriétés de la couche dans Qgis.
     
**** Évaluer la performance globale

     Nous allons maintenant utiliser l'application
     *ComputeConfusionMatrix* afin de calculer la performance globale
     de la classification. Par rapport à l'évaluation des
     performances réalisée lors de l'apprentissage, cette application
     permet de:
     - Prendre en compte l'ensemble des pixels disponibles dans la donnée de référence,
     - Évaluer la performance d'une carte de classification qui a été
    retraitée (par exemple avec une régularisation).
    
    Le paramètre ~ref.vector.field CODE~ est nécessaire. Il indique le
    nom du champ contenant le numéro de label.

    Calculer la performance globale de la classification. Que
     constatez vous par rapport à la performance évaluée lors de la
     phase d'entraînement ? Comment expliquer ce phénomène ?
     
**** Régulariser et mesurer le gain de performance

     Nous allons utiliser l'application *ClassificationMapRegularization*. Elle
     filtre une image classifiée en utilisant un vote majoritaire local.

     Les paramètres à régler sont:

  - ip.radius 1 :: Rayon de la zone participant au vote
  - ip.suvbool 0 :: Que faire lors d'une égalité. 0 pour utiliser la valeur existante.

  Filtrez le résultat de la classification précédente. Évaluer la
  performance globale de la carte de classification filtrée. Que
  constatez-vous ?

**** Réaliser une classification multi-date et mesurer le gain de performance

     Nous allons maintenant utiliser l'ensemble des dates pour la
     classification. A cet effet, vous pouvez utiliser le fichier
     ~images/all.vrt~ qui contient l'ensemble des bandes de chaque
     dates concaténées (c'est donc une image à 50 bandes). 

     Rejouer l'ensemble du TP avec cette image de 50 bandes. Quel est
     l'apport de la série multi-temporelle pour la performance de
     classification ?

     Comparez dans Qgis les deux cartes de classification régularisées.

**** Pour aller plus loin

     1) Peut on obtenir de meilleure performance avec d'autres
        algorithmes de classification ?
     
     2) A l'aide de Qgis, fusionner dans la donnée de référence les
        classes pelouse et lande ligneuse. Quelle performance obtenez
        vous ?

     3) L'application ~TrainImagesClassifier~ contient également un
        algorithme de classification non-supervisée (Shark
        KMeans). Comparer le résultat d'une classification supervisée
        et non-supervisée avec la même image. 

** Classification supervisée pour les séries multi-temporelles    :solutions:

Dans la correction suivante, la variable d'environnement ~$DATA~
correspond au répertoire contenant les données du TP (~Data/classification~).

*** Réaliser un apprentissage mono-date

L'apprentissage mono-date se réalise avec la commande suivante :

#+BEGIN_EXAMPLE
$ otbcli_TrainImagesClassifier -io.il $DATA/images/20160607_T31TCJ_ROI_20m.tif \
                               -io.vd $DATA/references/training/training.shp   \
                               -io.out model.rf                                \
                               -sample.vfn CODE -classifier rf                 \
                               -classifier.rf.nbtrees 50 -classifier.rf.max 20 \
                               -classifier.rf.cat 13
#+END_EXAMPLE

Cette première exécution donne les résultats suivants :
#+LATEX: \begin{small}
#+BEGIN_EXAMPLE
Confusion matrix (rows = reference labels, columns = produced labels):
       [10]  [31]  [32]  [34]  [36]  [41]  [42 ] [43]  [44]  [51] [211] [221] [222] 
[ 10]   374     3     0    26     1     6    19    11     2     0    13    10    13 
[ 31]     0   436     5     7    14     0     0     0     0     0     7     8     1 
[ 32]     3    16   420     6    15     0     0     0     0     0    12     3     3 
[ 34]    30    16    21   268    41     1    13     2     1     0    27    18    40 
[ 36]    10     6    13    31   336     0     7     0     0     0    42    13    20 
[ 41]     5     0     0     0     0   388    49    21    13     0     0     1     1 
[ 42]    31     1     3    10     3    44   288    36    22     0     0     5    35 
[ 43]    18     0     2    11     1    37    59   227   114     1     0     7     1 
[ 44]     7     0     3     3     2     5    10    71   371     0     0     5     1 
[ 51]     0     0     6     0     0     0     0     0     1   470     0     1     0 
[211]    19     7    13    41    64     0     3     0     0     0   266    14    51 
[221]    18    18     8    13    23     1    11     4     3     0    38   332     9 
[222]    22     0     1    30    12     0    14     0     0     0    16     4   379

[...]

Global performance, Kappa index: 0.710774

#+END_EXAMPLE
#+Latex: \end{small}

Ces performances sont cependant très optimistes, car les échantillons
utilisés pour les estimer proviennent des mêmes polygones. Pour
obtenir une évaluation plus réaliste des performances, il faut
utiliser un jeu de validation différent :

#+BEGIN_EXAMPLE
$ otbcli_TrainImagesClassifier -io.il $DATA/images/20160607_T31TCJ_ROI_20m.tif \
                               -io.vd $DATA/references/training/training.shp   \
                               -io.valid $DATA/references/testing/testing.shp  \
                               -io.out model.rf                                \
                               -sample.vfn CODE -classifier rf                 \
                               -classifier.rf.nbtrees 50 -classifier.rf.max 20 \
                               -classifier.rf.cat 13
#+END_EXAMPLE

Ce qui donne les résultats suivants :

#+LATEX: \begin{small}
#+BEGIN_EXAMPLE
Confusion matrix (rows = reference labels, columns = produced labels):
       [10]  [31]  [32]  [34]  [36]  [41]  [42]  [43]  [44]  [51] [211] [221] [222] 
[ 10]   795     6     6    47     9     4    13    18     0     0    22    10    23 
[ 31]     1   777    38    14    42     0     0     0     0     1    59    21     0 
[ 32]     1    34   865     3    12     2    14     1     1     0     2    15     3 
[ 34]    50   273   120    72    51     0     8     0     0    49   105   157    68 
[ 36]    23    27    45   186   336     0     1     1     0     0   215    79    40 
[ 41]     4     0     1     1     0   665   176    53    49     0     1     1     2 
[ 42]    20     1     3    11     2    98   652    75    43     0     5     8    35 
[ 43]    21     0     1    19     5    44   207   464   146     1     8    17    20 
[ 44]     7     0     1     3     0    13    23   240   662     0     0     4     0 
[ 51]     0     0     1     0     0     0     0     3     1   945     0     3     0 
[211]    81    21    17    81   112     1    16     4     0     0   507    40    73 
[221]    46    51    22    43    42     0    18    10     2     2   107   541    69 
[222]    70     0     0    68    23     0    71     1     0     0    45    11   664

[...]

Global performance, Kappa index: 0.611403
#+END_EXAMPLE
#+Latex: \end{small}

Si l'on désactive l'option ~cleanup~ en ajoutant le paramètre ~-cleanup
0~, l'application n'efface pas les sorties intermédiaires générées.

Les fichiers XML suivants contiennent les statistiques de nombre
d'échantillons disponibles par classe pour le jeu d'apprentissage et
celui de validation.
- ~model.rf_statsTrain_1.xml~
- ~model.rf_statsValid_1.xml~

Les fichiers Shapefile suivants contiennent les échantillons utilisés
pour l'apprentissage et pour la validation:
- ~model.rf_samplesTrain_1.shp~
- ~model.rf_samplesValid_1.shp~

Ces fichiers contiennent des points correspondant aux échantillons
sélectionnés dans les polygones d'apprentissage. Chaque point contient
un ensemble de primitives qui correspond aux radiométries mesurées à
cet endroit dans l'image. Ces deux fichiers peuvent être affichés dans
Qgis.

*** Identifier la date la plus performante


La commande suivante permet de réaliser l'apprentissage pour chaque
date. 

#+BEGIN_EXAMPLE
$ for f in $DATA/images/*.tif; do echo $f;            \
      otbcli_TrainImagesClassifier -io.il $f          \
      -io.vd $DATA/references/training/training.shp   \
      -io.valid $DATA/references/testing/testing.shp  \
      -sample.vfn CODE -classifier rf                 \
      -classifier.rf.nbtrees 50 -classifier.rf.max 20 \
      -classifier.rf.cat 13 -io.out model.rf   | grep Kappa; done
#+END_EXAMPLE

Les coefficients Kappa par date généré par cette commande sont les
suivants :

|------------+----------|
|       Date |    Kappa |
|------------+----------|
| 2016-06-07 | 0.609741 |
| 2016-07-07 | 0.615163 |
| 2016-08-06 | 0.593739 |
| 2016-09-05 | 0.614463 |
| 2016-10-05 | 0.622246 |
|------------+----------|

On constate que ce coefficient ne varie pas beaucoup, mais que la date
du ~2016-10-05~ obtient des performances légèrement meilleures.

*** Réaliser la classification et produire une carte en couleur

Pour réaliser la classification, on prend le fichier ~model.rf~ appris
sur la date ~2016-10-05~, et on utilise la commande suivante :

#+BEGIN_EXAMPLE
$ otbcli_ImageClassifier -in $DATA/images/20161005_T31TCJ_ROI_20m.tif \
                         -out classif_20161005.tif uint8              \
                         -model model.rf
#+END_EXAMPLE

L'image ~classif_20161005.tif~ contient pour chaque pixel le code de
la classe qui lui a été attribué. Afin de faciliter la lisibilité de
l'image, on peut transformer celle-ci en attribuant une couleur
différente à chaque classe en utilisant l'application de
*ColorMapping*:

#+BEGIN_EXAMPLE
$ otbcli_ColorMapping -in classif_20161005.tif            \
                      -out classif_20161005_rgb.tif uint8 \
                      -method custom -method.custom.lut   \ 
                      $DATA/support/color_map.txt
#+END_EXAMPLE

Une autre manière de visualiser l'image ~classif_20161005.tif~ est de
l'ouvrir dans QGis et d'utiliser le fichier de style fournit dans
~support/classif.qml~.

*** Évaluer la performance globale

 Pour évaluer les performances sur l'ensemble de la donnée de
 validation, on utilise l'application *ComputeConfusionMatrix*. Cette
 application complète l'évaluation réalisée lors de l'apprentissage,
 et permet d'évaluer la performance d'une carte de classification qui
 a éventuellement été retraitée. Attention à ne pas utiliser en entrée
 la carte colorisée créée à l'étape précédente, qui n'est utile qu'à
 des fins de visualisation et de publication.
 
 
 #+BEGIN_EXAMPLE
 $ otbcli_ComputeConfusionMatrix -in classif_20161005.tif -ref vector  \
                   -ref.vector.in $DATA/references/testing/testing.shp \
                                 -out confusion_20161005.csv           \
                                 -ref.vector.field CODE
#+END_EXAMPLE

La performance est évaluée en utilisant l'ensemble des données
disponibles dans le jeu de validation. Voici le résultat :

#+LATEX: \begin{scriptsize}
#+BEGIN_EXAMPLE
Confusion matrix (rows = reference labels, columns = produced labels):
       [  10] [  31] [  32] [  34] [  36] [  41] [  42] [  43] [  44] [  51] [ 211] [ 221] [ 222]
[  10] 113219    219   2240  10349   4090   2654   2469   1029    233    202   7387   2571   3453
[  31]      8  12282    265     66    346      0      5      1      0      0    174    192     27
[  32]      1     21   1143      5     27      0      2      0      0      0      3      7     10
[  34]    158     47     73   1469    146      9     68     25     12      0    187     11     70
[  36]     11      8      2      8    889      0      4      0      0      0     25      1     11
[  41]     45      0      4     34      7   4637    674    287    135      1      9      9     66
[  42]    800     14    107    675    355   5084  33947   3642   2684     13    468    490   3358
[  43]    816      4     97    417    130   2222   5399  18726   9404     66    137    171    857
[  44]     12      0      7      7      5     54    105    561   2807      6      0     13     27
[  51]    187     26     92     10     73      1     18    249    257  24330      4    300      4
[ 211]    367     73     55    882   1143      9     58      1      0      0   6755    126    301
[ 221]    244    337    372     79    338      2    197     49     16     32    174  10400    398
[ 222]     72      2     66     40    115      9    195      1      0      0     98     52   3474

Precision of class [10] vs all: 0.976531
Recall of class [10] vs all: 0.754215
F-score of class [10] vs all: 0.851095

[...]

Kappa index: 0.659139

#+END_EXAMPLE
#+Latex: \end{scriptsize}

On peut constater deux choses:
- Tout d'abord, la performance globale est légèrement meilleure que
  celle évaluée lors de l'apprentissage. Cela vient du fait que dans
  l'étape d'apprentissage, le même nombre d'échantillon est utilisé
  pour chaque classe, tandis que lors du calcul ci-dessus, l'ensemble
  des échantillons disponibles est utilisé. Certaines classes plus
  représentée et bien reconnue, comme la classe 51 (eau), tirent donc
  les performances globales vers le haut.
- Ensuite, la classe des cultures annuelles présente une assez forte
  confusion avec l'ensemble des autres classes. Elle présente un
  rappel de 0.75, et une précision de 0.97. Cela signifie que si 97%
  des éléments identifiés comme cultures annuels par le classifieur
  appartiennent effectivement à cette classe, 25% des éléments de
  cette classe dans la référence ont été mal classés. Nous allons voir
  par la suite que l'ajout d'une information multi-temporelle permet
  d'améliorer cette performance.

*** Régulariser et mesurer le gain de performance

Pour réaliser une régularisation par vote majoritaire, on utilise la commande suivante:

#+BEGIN_EXAMPLE
$ otbcli_ClassificationMapRegularization -ip.radius 1 -ip.suvbool 0  \
                                         -io.in classif_20161005.tif \
                                         -io.out classif_20161005_reg.tif uint8
#+END_EXAMPLE    

Si l'on évalue à nouveau les performances, on obtient :

#+BEGIN_EXAMPLE
$ otbcli_ComputeConfusionMatrix -in classif_20161005_reg.tif -ref vector  \
                   -ref.vector.in $DATA/references/testing/testing.shp    \
                                 -out confusion_20161005_reg.csv          \
                                 -ref.vector.field CODE

Kappa index: 0.709103
#+END_EXAMPLE

La régularisation améliore donc significativement les
performances. Ceci s'explique par la régularité de la donnée de
référence, dont on se rapproche avec ce type de traitement.

*** Réaliser une classification multi-date et mesurer le gain de performance

Rejouons les différentes étapes avec l'ensemble des dates:


Tout d'abord, l'apprentissage :
#+BEGIN_EXAMPLE
$ otbcli_TrainImagesClassifier -io.il $DATA/images/all.vrt                     \
                               -io.vd $DATA/references/training/training.shp   \
                               -io.valid $DATA/references/testing/testing.shp  \
                               -io.out model_all.rf                            \
                               -sample.vfn CODE -classifier rf                 \
                               -classifier.rf.nbtrees 50 -classifier.rf.max 20 \
                               -classifier.rf.cat 13
#+END_EXAMPLE

Ensuite, la classification :
#+BEGIN_EXAMPLE
$ otbcli_ImageClassifier -in $DATA/images/all.vrt    \
                         -out classif_all.tif uint8  \
                         -model model_all.rf
#+END_EXAMPLE

Puis la régularisation :
#+BEGIN_EXAMPLE
$ otbcli_ClassificationMapRegularization -ip.radius 1 -ip.suvbool 0  \
                                         -io.in classif_all.tif \
                                         -io.out classif_all_reg.tif uint8
#+END_EXAMPLE   

Enfin, l'évaluation des performances globales:
#+BEGIN_EXAMPLE
$ otbcli_ComputeConfusionMatrix -in classif_all_reg.tif -ref vector       \
                   -ref.vector.in $DATA/references/testing/testing.shp    \
                                 -out confusion_all_reg.csv               \
                                 -ref.vector.field CODE
#+END_EXAMPLE

#+Latex:\begin{scriptsize}
#+BEGIN_EXAMPLE
Confusion matrix (rows = reference labels, columns = produced labels):
       [  10] [  31] [  32] [  34] [  36] [  41] [  42] [  43] [  44] [  51] [ 211] [ 221] [ 222] 
[  10] 140681     13     68   1893    790    280    494    545     27    108   3569    383   1264 
[  31]     19  12732     87     77    200      3      8      0      0      0    104    131      5 
[  32]      1      6   1211      0      1      0      0      0      0      0      0      0      0 
[  34]      0     32     23   2131     34      0     12     13      0      0     19      5      6 
[  36]      0      0      0      4    937      0      4      0      0      0      8      0      6 
[  41]      2      0      1      0      0   5369    330    111     87      1      0      7      0 
[  42]    148     10     75    465     84   3166  41818   2943   1850      2    316    362    398 
[  43]    143      6     67    528     57   1545   5556  21781   8265     35    166    195    102 
[  44]     11      0     14     13      0     34     60    354   3108      0      2      8      0 
[  51]      7     18     53      0     12      0      3     37     24  25319      2     76      0 
[ 211]    213     41     17    444    491      8     45      1      0      0   8326    104     80 
[ 221]    187     87     66    123    159      0    109     83      3     14    208  11374    225 
[ 222]     29      0      2     15     41      4     42      0      0      0     43     11   3937 

Precision of class [10] vs all: 0.994627
Recall of class [10] vs all: 0.937155
F-score of class [10] vs all: 0.965036

[...]

Kappa index: 0.828411

#+END_EXAMPLE
#+LATEX:\end{scriptsize}

L'ajout de l'information multi-temporelle dans la classification a
permis d'améliorer significativement les performances. On peut
constater notamment que le rappel de la classe cultures annuelles a
augmenté jusqu'à 93%, ce qui signifie que désormais 93% des éléments
de cette classe présents dans la vérité terrain sont correctement
identifiés par le classifieur. Cette amélioration était attendue car
les classes de cultures présentent une dynamique temporelle
distinctive, par rapport à d'autres classes.

On peut enfin générer la carte de classification colorisée finale :

#+BEGIN_EXAMPLE
$ otbcli_ColorMapping -in classif_all_reg.tif            \
                      -out classif_all_reg_rgb.tif uint8 \
                      -method custom -method.custom.lut  \ 
                      $DATA/support/color_map.txt
#+END_EXAMPLE
